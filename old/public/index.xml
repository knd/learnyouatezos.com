<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Latte, Jed?</title>
    <link>http://lattejed.com/index.xml</link>
    <description>Recent content on Latte, Jed?</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Feb 2017 10:34:12 +0700</lastBuildDate>
    <atom:link href="http://lattejed.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Rendering Basics with Metal iOS</title>
      <link>http://lattejed.com/pages/rendering-basics-with-metal-ios/</link>
      <pubDate>Mon, 27 Feb 2017 10:34:12 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/rendering-basics-with-metal-ios/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;http://model3d.co&#34;&gt;Model3D&lt;/a&gt; &amp;ndash; 3D modeling software we&amp;rsquo;re in the process of launching for iPad &amp;ndash; is built on the new GPU API &lt;a href=&#34;https://developer.apple.com/metal/&#34;&gt;Metal&lt;/a&gt;. Metal lives up to its name (close to the metal) and is decidedly pretty awesome, especially when working with the more powerful iPad Pro. There isn&amp;rsquo;t that much written about Metal so I&amp;rsquo;m going to cover some of the basics, as well as some 3D basics, here.&lt;/p&gt;

&lt;h3 id=&#34;metal-is-a-thin-layer-over-apple-hardware&#34;&gt;Metal is a Thin Layer Over Apple Hardware&lt;/h3&gt;

&lt;p&gt;Metal is high performance because it&amp;rsquo;s a thin layer over a small set of GPU hardware. While I won&amp;rsquo;t go into the details, it eliminates most of the overhead of OpenGL as it doesn&amp;rsquo;t have to worry about supporting a wide range of hardware on different platforms. In other words, it&amp;rsquo;s trading performance for portability. If you&amp;rsquo;re developing graphics software specifically for iOS (or macOS) then it&amp;rsquo;s probably worth the trade off.&lt;/p&gt;

&lt;h3 id=&#34;metal-is-not-opinionated&#34;&gt;Metal is Not Opinionated&lt;/h3&gt;

&lt;p&gt;One of the more challenging things about Metal, at least starting out, is that it&amp;rsquo;s &lt;em&gt;not&lt;/em&gt; opinionated. Apple&amp;rsquo;s documentation and sample code will not show you one way to work with Metal, but many. This does add to the confusion of working with the technology, but since Metal is optimized for performance, this hands off approach is appropriate. In fact, Model3D uses Metal in different ways in the same project &amp;ndash; the 3D controls, for example, are rendered differently than the objects in the workspace.&lt;/p&gt;

&lt;h3 id=&#34;3d-basics&#34;&gt;3D Basics&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/3d-basics.jpg&#34; alt=&#34;3D Basics&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Just in case you&amp;rsquo;re a new to 3D, this covers the basic terminology. Vertices are points in 3D space which are transformed to the 2D space of the screen during rendering. Vertices can be drawn individually as points (with an arbitrary pixel radius). Lines can be draw between vertices. In Metal, a line is always 1px in width. Solids are drawn as a set of triangles, being defined by a set of vertices &lt;em&gt;and&lt;/em&gt; a set of indices. These are generally drawn in counter-clockwise order where ccw-drawn triangles are front-facing and cw-drawn triangles are rear facing. (This can be reversed.) Face is a fairly loose term as it can mean a single triangle or a set of triangles that form a polygon aligned to a plane.&lt;/p&gt;

&lt;h3 id=&#34;high-level-rendering&#34;&gt;High Level Rendering&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/metal-high-level-diagram.jpg&#34; alt=&#34;Metal Diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Very high level, what we&amp;rsquo;re doing here is to allocate some memory for a texture (a rendering destination), doing some boilerplate pipeline setup, creating a bunch of draw commands and then executing the whole thing. If we&amp;rsquo;re rendering to the screen, that last step will include a &lt;code&gt;+[MTLCommandBuffer presentDrawable:]&lt;/code&gt; if we&amp;rsquo;re rendering to a texture (to, say, create a UIImage) it will not.&lt;/p&gt;

&lt;p&gt;All of the magic of rendering is going to happen in the &amp;ldquo;draw commands&amp;rdquo; part of that diagram.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/draw-command-high-level.jpg&#34; alt=&#34;Draw Command Diagram&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The first part of the draw command is assigning memory to the pipeline. This can be &amp;ldquo;uniform&amp;rdquo; structs &amp;ndash; small amounts of memory that will get copied over to GPU memory and be available for shaders. If you&amp;rsquo;re new to graphics programming they&amp;rsquo;re called &amp;ldquo;uniforms&amp;rdquo; because they&amp;rsquo;re the same for each call of the shader, where as, e.g., the vertex data will be different for each call to the shader. The uniform struct might carry a camera / projection matrix (usually a 4x4 matrix of floats) that we&amp;rsquo;ll multiply our vertex positions by (more on that later).&lt;/p&gt;

&lt;p&gt;Note we&amp;rsquo;re saying &lt;em&gt;assign&lt;/em&gt; memory and not allocate. Very small amounts of memory (say under 4kb) may be allocated and assigned each frame, but larger amounts of memory (e.g., vertex data) should be allocated once, or infrequently, and reused. Again, there are many ways to do this and no one correct way.&lt;/p&gt;

&lt;p&gt;The &amp;ldquo;set pipeline state&amp;rdquo; here refers to &lt;code&gt;-[MTLRenderCommandEncoder setRenderPipelineState:]&lt;/code&gt; and is where we&amp;rsquo;ll assign our shaders. This pipeline state is specific to the draw commands that will follow and can be reset to another state any number of times before execution.&lt;/p&gt;

&lt;p&gt;The actual draw commands will either be executed once per vertex in memory &lt;code&gt;-[MTLRenderCommandEncoder drawPrimitives:vertexStart:vertexCount:]&lt;/code&gt; or will take an additional index buffer and be executed once per index &lt;code&gt;-[MTLRenderCommandEncoder drawIndexedPrimitives:indexCount: indexType:indexBuffer:indexBufferOffset:]&lt;/code&gt;. The former is useful for drawing points whereas the latter is useful for drawing triangles for solid surfaces.&lt;/p&gt;

&lt;h3 id=&#34;model3d-renderer&#34;&gt;Model3D Renderer&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;- (void)render:(CAMetalLayer *)layer {
    
    id&amp;lt;CAMetalDrawable&amp;gt; currentDrawable = [layer nextDrawable];
    id&amp;lt;MTLCommandBuffer&amp;gt; commandBuffer = [self.commandQueue commandBuffer];
    MTLRenderPassDescriptor* pass = [self renderPass:currentDrawable.texture];
    
    id&amp;lt;MTLRenderCommandEncoder&amp;gt; encoder;
    encoder = [commandBuffer renderCommandEncoderWithDescriptor:pass];
    [encoder setFrontFacingWinding:MTLWindingCounterClockwise];
    [encoder setCullMode:MTLCullModeBack];

    for (id&amp;lt;BLKRenderable&amp;gt; renderable in _renderables) {
        [renderable render:encoder device:_device];
    }
    
    [encoder endEncoding];
    
    [commandBuffer presentDrawable:currentDrawable];
    [commandBuffer commit];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The renderer in Model3D is no more complicated than that. The &lt;code&gt;commandQueue&lt;/code&gt; is cached at startup. The &lt;code&gt;CAMetalDrawable&lt;/code&gt; is passed in via the &lt;code&gt;CAMetalLayer&lt;/code&gt;. The rendering is &amp;ldquo;driven&amp;rdquo; via a &lt;code&gt;CADisplayLink&lt;/code&gt;. In this case the display link is set to fire 60 times per second.&lt;/p&gt;

&lt;p&gt;The actual drawing duties are offloaded to our &lt;code&gt;BLKRenderable&lt;/code&gt; protocol.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;@protocol BLKRenderable &amp;lt;NSObject&amp;gt;

- (NSUInteger)renderOrder;
- (void)render:(id&amp;lt;MTLRenderCommandEncoder&amp;gt;)encoder device:(id&amp;lt;MTLDevice&amp;gt;)device;

@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this protocol, instead of having the renderer handle everything centrally, allows us to draw things in a way that is most appropriate to the situation.&lt;/p&gt;

&lt;h3 id=&#34;workspace-object-rendering&#34;&gt;Workspace Object Rendering&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/apc-render-full.jpg&#34; alt=&#34;APC Render&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The most efficient way to manage memory for workspace objects (the objects we&amp;rsquo;re editing) is different than it would be if we were rendering geometry for a game and it&amp;rsquo;s also different than how we&amp;rsquo;re managing memory for other objects on our screen (e.g., control objects, 2D lines, etc.).&lt;/p&gt;

&lt;p&gt;Workspace objects are very dynamic. The total number of vertices may change often and the position of those vertices will change constantly. Our triangle indices may change as well. Because of that we want to manage our memory in a way where it&amp;rsquo;s relatively inexpensive to update our vertex data. Because of that we&amp;rsquo;ll use the most &amp;ldquo;hands on&amp;rdquo; approach and manually allocate our memory.&lt;/p&gt;

&lt;p&gt;Because this memory has to be shared between the CPU and GPU, we can&amp;rsquo;t simply use &lt;code&gt;malloc&lt;/code&gt;. We&amp;rsquo;re going to have to use a combination of &lt;code&gt;getpagesize&lt;/code&gt; and &lt;code&gt;posix_memalign&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;- (NSInteger)pageSize {
    return getpagesize();
}

- (NSInteger)vertexMemorySize {
    NSInteger bytes = 0;
    for (BLKObject* obj in _objects) {
        for (BLKFace* face in obj.faces) {
            bytes += sizeof(vertex_data) * face.vertices.count;
        }
    }
    NSInteger ps = [self pageSize];
    // Round up to next page size multiple
    return (int)ceil((double)bytes / (double)ps) * ps;
}

- (void)buildVertexMemory:(id&amp;lt;MTLDevice&amp;gt;)device {
    if (_vertexMemory != NULL) {
        free(_vertexMemory);
        _vertexMemory = NULL;
    }
    NSUInteger size = [self vertexMemorySize];
    posix_memalign(&amp;amp;_vertexMemory, [self pageSize], size);
    _vertexBuffer = [device
                     newBufferWithBytesNoCopy:_vertexMemory
                     length:size
                     options:MTLResourceCPUCacheModeWriteCombined
                     deallocator:nil];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is short but there&amp;rsquo;s actually quite a bit going on here. &lt;code&gt;getpagesize&lt;/code&gt; is actually deprecated but is this the correct way to get the page size of the current hardware. What the page size is differs for different hardware. From Apple docs:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In OS X and in earlier versions of iOS, the size of a page is 4 kilobytes. In later versions of iOS, A7- and A8-based systems expose 16-kilobyte pages to the 64-bit userspace backed by 4-kilobyte physical pages, while A9 systems expose 16-kilobyte pages backed by 16-kilobyte physical pages.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The short answer is don&amp;rsquo;t hard code it and you won&amp;rsquo;t have to worry about it. Our method &lt;code&gt;buildVertexMemory&lt;/code&gt; is only called when the total number of vertices changes (e.g., and object is added to or deleted from our workspace). It is not called when the vertex data changes and certainly not called every frame.&lt;/p&gt;

&lt;p&gt;The option &lt;code&gt;MTLResourceCPUCacheModeWriteCombined&lt;/code&gt; is appropriate if we&amp;rsquo;re going to manage the memory ourselves and that memory will be written to (but not read by) the CPU (i.e., our program logic). By calling &lt;code&gt;-[MTLDevice newBufferWithBytesNoCopy:length:options:deallocator:&lt;/code&gt; we ensure that memory is not allocated (or managed by) Metal and it&amp;rsquo;s going to use our chunk of page-aligned memory. The effect is that we can now write to the pointer &lt;code&gt;(vertex_data*)_vertexMemory&lt;/code&gt; like any other C array and the GPU will see our updates without further intervention.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;- (void)render:(id&amp;lt;MTLRenderCommandEncoder&amp;gt;)encoder device:(id&amp;lt;MTLDevice&amp;gt;)device {
    
    BLKRenderer* rend = [BLKRenderer sharedRenderer];
    
    // Update memory if necessary
    // Update data if necessary
    
    camera_uniform_data uni;
    simd::float4x4 cm = _mainCamera.matrix;
    uni.cm = self.proj_perspective * cm;
    
    [encoder setVertexBytes:&amp;amp;uni length:sizeof(camera_uniform_data) atIndex:1];
    [encoder setVertexBuffer:_vertexBuffer offset:0 atIndex:0];
    
    NSInteger vboffset = 0;
    NSInteger iboffset = 0;
    
    for (BLKObject* obj in _objects) {
        
        [encoder setVertexBufferOffset:vboffset atIndex:0];
        
        vboffset += sizeof(vertex_data) * obj.vertCount;
        
        // Solid pass

        [encoder setRenderPipelineState:rend.solidPipelineState];
        [encoder setDepthStencilState:rend.depthStencilA];

        [encoder drawIndexedPrimitives:MTLPrimitiveTypeTriangle
                            indexCount:obj.triCount * 3
                             indexType:MTLIndexTypeUInt32
                           indexBuffer:_indexBuffer
                     indexBufferOffset:iboffset];
        
        iboffset += sizeof(index_data) * obj.triCount * 3;

        // Edge pass
        
        [encoder setRenderPipelineState:rend.edgePipelineState];
        [encoder setDepthStencilState:rend.depthStencilA];
        
        [encoder drawIndexedPrimitives:MTLPrimitiveTypeLine
                            indexCount:obj.edgeCount * 2
                             indexType:MTLIndexTypeUInt32
                           indexBuffer:_indexBuffer
                     indexBufferOffset:iboffset];
        
        iboffset += sizeof(index_data) * obj.edgeCount * 2;

        // Point pass
            
        [encoder setRenderPipelineState:rend.pointPipelineState];
        [encoder setDepthStencilState:rend.depthStencilA];
        
        [encoder drawPrimitives:MTLPrimitiveTypePoint
                    vertexStart:0
                    vertexCount:obj.vertCount];
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll notice we&amp;rsquo;re settings our pipeline state three times &amp;ndash; solid, edge and point. These represent both vertex and fragment shaders. If you&amp;rsquo;re not familiar, a shader is the actual program executed, in parallel, by the GPU to render our data into a texture. Although it&amp;rsquo;s not the only way to do it, in this case we&amp;rsquo;re running a vertex shader followed by a fragment shader. A vertex shader is generally run once per vertex. In the case of our solid pass, each vertex may be used more than once as they&amp;rsquo;re shared between independent triangles. For our point pass, each vertex will be used once.&lt;/p&gt;

&lt;p&gt;Our fragment (pixel) shader is going to take the interpolated result of our vertex shaderand allow us to draw per-pixel to our destination.&lt;/p&gt;

&lt;p&gt;In their simplest form, these will look something like:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;vertex io_vertex 
vertex_solid(device vertex_data* vertices [[buffer(0)]],
             uint vid [[vertex_id]],
             constant camera_uniform_data&amp;amp; cuni [[buffer(1)]]) {
    io_vertex overt;
    vertex_data vert = vertices[vid];
    overt.position = cuni.cm * vert.pos;
    overt.color = vert.solid_color;
    return overt;
}

fragment float4 
fragment_simple(io_vertex vert [[stage_in]]) {
    return vert.color;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see the fragment (pixel) shader is just passing along the color we&amp;rsquo;ve sent to it. Our vertex shader, in this case, is taking our uniform data, specifically our camera + projection matrix and multiplying our vertex position by it. This could have also been done in our &lt;code&gt;-render:device:&lt;/code&gt; method, by the CPU, but that would mean not taking advantage of the parallel processing capabilities of the GPU.&lt;/p&gt;

&lt;p&gt;You will also notice in the &lt;code&gt;-render:device:&lt;/code&gt; method that we&amp;rsquo;re keeping track of offsets manually. That&amp;rsquo;s because our memory is laid out something along the lines of:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/workspace-mem-layout.jpg&#34; alt=&#34;Workspace Memory Layout&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We have a single block of memory for vertices (typed &lt;code&gt;vertex_data*&lt;/code&gt;) and a single block of memory for both triangle and edge indices (typed &lt;code&gt;unsinged int*&lt;/code&gt;). Again, this isn&amp;rsquo;t the only way we can do it, but in this case this is the best way to do it.&lt;/p&gt;

&lt;p&gt;Other renderables (our control objects, 2D lines, etc.) are each managed somewhat differently, but I won&amp;rsquo;t go into them in depth here.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why my Nom de Guerre is Latte Jed</title>
      <link>http://lattejed.com/pages/why-my-nom-de-guerre-is-latte-jed/</link>
      <pubDate>Fri, 22 Jul 2016 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/why-my-nom-de-guerre-is-latte-jed/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve been asked a few times why I go by &amp;ldquo;Latte, Jed?&amp;rdquo; online. I know I&amp;rsquo;m dating myself here but I grew up on the cartoonist Gary Larson&amp;rsquo;s &lt;em&gt;The Far Side&lt;/em&gt;. If you haven&amp;rsquo;t already, avail yourself of his work. He&amp;rsquo;s undoubtedly the king of surrealist cartoons &amp;ndash; lighthearted but intelligent.&lt;/p&gt;

&lt;p&gt;The panel in question is this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/latte_jed.jpg&#34; alt=&#34;Latte, Jed?&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Keep in mind that at the time he drew this coffee culture in America was nothing like it is today. A &lt;em&gt;caffè latte&lt;/em&gt; was a relatively exotic thing, so having a cowboy produce an espresso machine was particularly funny.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why I&#39;ve Lost Faith in Ethereum and Won&#39;t Invest in ETH</title>
      <link>http://lattejed.com/pages/why-ive-lost-faith-in-ethereum-and-wont-invest-in-eth/</link>
      <pubDate>Wed, 20 Jul 2016 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/why-ive-lost-faith-in-ethereum-and-wont-invest-in-eth/</guid>
      <description>&lt;p&gt;A discussion of the immenent fork of Ethereum came up &lt;a href=&#34;https://news.ycombinator.com/item?id=12125515&#34;&gt;on Hacker News&lt;/a&gt; today (I think the fork actually happened as of the time of writing this) and someone suggested that the ability to fork, e.g., change the rules of the game gives Ethereum an advantage over &amp;ldquo;more conservative&amp;rdquo; alternatives such as bitcoin. I think to say that totally misses the point. Quoting myself:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I think [saying forking is somehow positive is] entirely too apologetic. The innovation was the original protocol. They were premature (as a lot of people warned) setting up anything as massive as the DAO, someone found a way to creatively interpret the rules and make a lot of money. Instead of sucking it up as a very expensive bug bounty, they decided to manipulate the entire system &amp;ndash; going against the very essence of that system.&lt;/p&gt;

&lt;p&gt;The DAO&amp;rsquo;s own terms state: &amp;ldquo;Any and all explanatory terms or descriptions are merely offered for educational purposes and do not supercede or modify the express terms of The DAO’s code set forth on the blockchain; to the extent you believe there to be any conflict or discrepancy between the descriptions offered here and the functionality of The DAO’s code at 0xbb9bc244d798123fde783fcc1c72d3bb8c189413, The DAO’s code controls and sets forth all terms of The DAO Creation.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Obviously the hacker&amp;rsquo;s intent was theft but under the DAO&amp;rsquo;s own terms it was a valid activity.&lt;/p&gt;

&lt;p&gt;Basically the code is law. If we&amp;rsquo;re going to then interpret that law then we&amp;rsquo;ve created a system similar to the current systems we have, but lacking in maturity. The point of something like Ethereum is not that it can&amp;rsquo;t be manipulated, it&amp;rsquo;s that it doesn&amp;rsquo;t need to be in order to function. It can be trusted explicitly because its functionality is not open to interpretation.&lt;/p&gt;

&lt;p&gt;If I&amp;rsquo;m not being clear enough &amp;ndash; what they should have done is taken this as a very expensive lesson and otherwise left the system alone. Yes, a &amp;ldquo;bad person&amp;rdquo; would have profited but the system&amp;rsquo;s integrity would have been untouched.&lt;/p&gt;

&lt;p&gt;FWIW, I was an early backer of Ethereum and bought ETH during the pre-sale. I invested because I thought it was promising &amp;ndash; without any real expectation of return. Coincidentally I sold all of my ETH just before this hack (40x ROI). Because of the fork I would not invest in ETH again, regardless of potential returns, because Ethereum is no longer what it set out to be.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I won&amp;rsquo;t belabor the point but yeah, I used to think it was great idea and worth investing in &amp;ndash; now it&amp;rsquo;s simply too compromised to be taken seriously.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Why this Site is now Self Hosted</title>
      <link>http://lattejed.com/pages/why-this-site-is-now-self-hosted/</link>
      <pubDate>Tue, 19 Jul 2016 19:36:48 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/why-this-site-is-now-self-hosted/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Note: While this site is still self-hosted, it&amp;rsquo;s now managed by Hugo so most of what&amp;rsquo;s below doesn&amp;rsquo;t apply&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This site, now in its &lt;del&gt;current brutalist form&lt;/del&gt;, has been hosted in a few different places over the years. I don&amp;rsquo;t write that often but I&amp;rsquo;ve made some effort to maintain a site since I got into software. That&amp;rsquo;s usually meant picking a decent blog hosting platform and writing something about 1/10th of the times I&amp;rsquo;ve thought I should. I&amp;rsquo;ve used Tubmlr, Posterous, Posthaven (the post sale reboot of Posterous), GitHub and was considering Medium and then said fuck it, I&amp;rsquo;ll just put it on a server somewhere and be done with it.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s why:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Simplicity. A static website is an exceedingly simple thing. I&amp;rsquo;d rather just write one in vim than deal with a webpage-as-text-editor.&lt;/li&gt;
&lt;li&gt;Style. &lt;del&gt;While this site may be (intentionally) ugly&lt;/del&gt;, it was exaclty what I wanted and didn&amp;rsquo;t require dealing with a theme interface nor did someone else decide what my site should look like for aesthetic or technlogical reasons.&lt;/li&gt;
&lt;li&gt;Dumbed down services. Hosting a site for any length of time almost invariably requires redirects or file hosting or a form or whatever. Existing services don&amp;rsquo;t provide some or all of these.&lt;/li&gt;
&lt;li&gt;Performance. It&amp;rsquo;s really hard to beat a VPS from a decent provider (I use Digital Ocean) with CloudFlare&amp;rsquo;s free plan as a CDN. If my site is simple I expect it to load in a microsecond. Most servies aren&amp;rsquo;t that great.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I was actually hosting this most recent version on GitHub. GitHub&amp;rsquo;s offering has a lot of nerd appeal. You can edit locally, deploy with a &lt;code&gt;git push&lt;/code&gt;, they&amp;rsquo;ve got a CDN (as far as I know) and it&amp;rsquo;s free or included in whatever plan you&amp;rsquo;ve already got with them.&lt;/p&gt;

&lt;p&gt;Then I spent 45 minutes trying to figure out how people set up 301s when using gh-pages and was disappointed to find out they don&amp;rsquo;t. Some people recommend using refresh and canonical meta tags on a basic page (supposedly SEO acceptible). There&amp;rsquo;s even a Jekyll plugin for it. To me that just sounds silly.&lt;/p&gt;

&lt;p&gt;Also, Jekyll. Whenever you push to GitHub it treats your site as a Jekyll site and tries to &amp;ldquo;compile&amp;rdquo; it. Even if it&amp;rsquo;s not a Jekyll site. It fails sometime without reason and &amp;ldquo;fixing&amp;rdquo; it usually means pushing empty commits until it works.&lt;/p&gt;

&lt;p&gt;Anyway, my point wasn&amp;rsquo;t to complain about hosting a site on GitHub, but rather the fact that these services will likely end up costing you more time than they&amp;rsquo;re worth. Setting up nginx or apache to host a static site isn&amp;rsquo;t very complicated and it&amp;rsquo;s a much better skill to learn than the quirks of some service.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Writing an Embedded Full Text Search Engine</title>
      <link>http://lattejed.com/pages/writing-an-embedded-full-text-search-engine/</link>
      <pubDate>Tue, 06 Oct 2015 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/writing-an-embedded-full-text-search-engine/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Note: While this monster post should be of interest to anyone working on full text search, I no longer recommend the approach outlined here. 1) In practice, Levenshtein indexes don&amp;rsquo;t give a real advantage vs a properly implemented n-gram index. 2) Levenshtein indexes, even using the technique below, take up too much space. 3) LevelDB isn&amp;rsquo;t a good choice for this&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m currently working on a project and had the opportunity to write an embedded search engine for it. I say opportunity because this is the kind of project that is lots of fun and would be a hard sell to a team. That is, even though there isn&amp;rsquo;t a go-to embeddable search engine, one could almost certainly be put together with existing libraries at a much higher level than how I wrote this one. SQLite, for example, which is more or less the go-to DB for apps, has support for full text search. Apple has SearchKit, which is far from complete or easy to use, but nevertheless would likely be much faster than writing something from scratch.&lt;/p&gt;

&lt;p&gt;From scratch is a very nebulous phrase in software development since it&amp;rsquo;s exceedingly rare to write something that isn&amp;rsquo;t built on a whole lot of other, preexisting stuff. This project is no different and while it&amp;rsquo;s about as low level as you&amp;rsquo;d want to get when writing a search engine, it is based on a set of libraries, most notably LevelDB and ICU. LevelDB is an embedded key-value store that is tiny and fast and has a good pedigree. Like SQLite, LevelDB does not run as a separate process and does not have a client-server model. It gets compiled into your app. Hence the embedded part. ICU is the de facto standard for dealing with Unicode &amp;ndash; dealing with things like text tokenization in problematic languages like Chinese as well as Unicode normalization and a host of other things.&lt;/p&gt;

&lt;p&gt;So I didn&amp;rsquo;t really start from scratch. I started from a sane set of base libraries. From there however it&amp;rsquo;s still a lot of work to build something that can store and search a set of documents. Before I get into the how I should take a moment to address the why.&lt;/p&gt;

&lt;h3 id=&#34;why-build-a-search-engine-from-scratch&#34;&gt;Why Build a Search Engine from Scratch?&lt;/h3&gt;

&lt;p&gt;This is a great question. The high level answer is that I want an end result that is blazingly fast and very accurate. I want something lightweight enough that it can run on OS X as well as iOS or other mobile devices. Now, as a software engineer, I have to be able to answer the question, &amp;ldquo;Is alternative X or Y lacking in any measurable way that is relevant to the application at hand?&amp;rdquo; The problem with that is it&amp;rsquo;s not possible to benchmark a piece of software that hasn&amp;rsquo;t been written yet so I can&amp;rsquo;t say if this approach is better than using SQLite or SearchKit. While I could have tested the performance and features of SQLite and SearchKit, the reality is that I decided to write one from scratch for this project for emotional reasons &amp;ndash; because I wanted to. When this is production-ready it certainly will be interesting to benchmark it against something like SQLite.&lt;/p&gt;

&lt;h3 id=&#34;high-level-design&#34;&gt;High Level Design&lt;/h3&gt;

&lt;p&gt;So what is a full text search engine? The goal is to end up with a black box that contains a bunch of documents that can be queried for a word or a phrase. The simplest approach would be to have a set of documents on disk (or in memory) and go through them one by one, breaking them into terms and checking if our search term matches any of those. In essence that&amp;rsquo;s what every search engine does except that practical designs will do a lot of pre-processing to speed up that matching.&lt;/p&gt;

&lt;p&gt;A more usable design will take pieces of the documents and create one or more indexes. These indexes are shortcuts &amp;ndash; a manifestation of the ability to trade off between processing time and disk space. The most basic index for full text search would be a word index (in this context usually called an inverted index) &amp;ndash; a list of words that point to the documents that contain them. Here we take up some more space (size of documents + size of word index) but gain the ability to scan through a smaller list of words (alphabetized, duplicates and unimportant words removed) to find matches. Instead of searching all of the documents for the word &amp;ldquo;beautiful&amp;rdquo; we search the index for the word. We can then fetch the set of documents with the word &amp;ldquo;beautiful&amp;rdquo; in them and do some other stuff to decide if those documents are the ones we want or not.&lt;/p&gt;

&lt;p&gt;If all we want to do is find exact matches, we&amp;rsquo;re actually most of the way there. This very simple index will allow us to find documents with the word &amp;ldquo;beautiful&amp;rdquo; in them if the following conditions are met:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The word beautiful is spelled correctly as a search term.&lt;/li&gt;
&lt;li&gt;The word beautiful is spelled correctly in the document that contains it.&lt;/li&gt;
&lt;li&gt;The word beautiful doesn&amp;rsquo;t have a prefix or suffix, e.g., &amp;ldquo;beautifully&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The word beautiful was tokenized properly (related to #3).&lt;/li&gt;
&lt;li&gt;And others&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The point is this type of all or nothing term search is exceedingly fragile when dealing with human language and human operators. To improve on this, we&amp;rsquo;ll need some manner of approximate or &amp;ldquo;fuzzy&amp;rdquo; matching of terms. When we&amp;rsquo;re talking about matching terms based on similarity we&amp;rsquo;re usually going to look at some type of edit distance, like &lt;a href=&#34;https://en.wikipedia.org/wiki/Levenshtein_distance&#34;&gt;Levenshtein distance&lt;/a&gt; (which is what we will eventually use here), but there are interesting alternatives such as &lt;a href=&#34;http://blog.nishtahir.com/2015/09/19/fuzzy-string-matching-using-cosine-similarity/&#34;&gt;cosine similarity&lt;/a&gt;. Regardless of how we determine it, we&amp;rsquo;re calculating how similar our search term is with the terms in each document. For example the words &amp;ldquo;that&amp;rdquo; and &amp;ldquo;than&amp;rdquo; have a Levenshtein distance of 1 (one substitution) and a cosine similarity of ~0.8164 (a score of 1 meaning identical, 0 meaning no similarity). What we consider &amp;ldquo;close enough&amp;rdquo; is an arbitrary threshold.&lt;/p&gt;

&lt;p&gt;A naive &amp;ldquo;fuzzy&amp;rdquo; approach would be to calculate the edit distance of our search term against each word in our index. Again, this will be slow as we&amp;rsquo;ll be spending most of our time comparing words that have little or no similarity. While not as bad as testing every word in every document, it&amp;rsquo;s still far from ideal. We could try to speed this up by doing things like only testing words that share a common prefix, but there are plenty of cases where that will fail, such as a spelling error in the first few letters of a word. If we want something more robust we&amp;rsquo;re going to have to get more creative.&lt;/p&gt;

&lt;h3 id=&#34;precomputed-n-gram-index&#34;&gt;Precomputed N-Gram Index&lt;/h3&gt;

&lt;p&gt;Since we want to trade disk space for processing time, we want to do as much of the work required for searching ahead of time as possible. That will lead us to an index that is larger and more complex. One of the more common types of precomputed indexes is an n-gram index. N-grams (unigrams, bigrams, trigrams, &amp;hellip;, 25-grams, &amp;hellip;) in this case are our words broken into groups of n letters. Our word &amp;ldquo;beautiful&amp;rdquo; could be broken into the trigrams, &amp;ldquo;bea&amp;rdquo;, &amp;ldquo;eau&amp;rdquo;, &amp;ldquo;aut&amp;rdquo;, &amp;ldquo;uti&amp;rdquo;, etc. What n-grams allow us to do is search for partial word matches. We&amp;rsquo;ll end up fetching a lot of unrelated words (there&amp;rsquo;s an &amp;ldquo;aut&amp;rdquo; in &amp;ldquo;flautist&amp;rdquo;) but the total number will probably be a reasonable amount to do another round of testing for a match (such as calculating cosine similarity). N-grams are neat. They&amp;rsquo;re almost an ideal, universal solution to our problem and they&amp;rsquo;re conceptually very simple.&lt;/p&gt;

&lt;p&gt;Where they fall down, however, is their ability to deal with incorrect spelling. It&amp;rsquo;s fairly likely that two words can be similar (in terms of their edit distance) but have zero trigrams in common. (For reasons beyond the scope of this, n-grams for partial word matches are almost always trigrams.) An example would be &lt;a href=&#34;http://ntz-develop.blogspot.com/2011/03/fuzzy-string-search.html&#34;&gt;&amp;ldquo;vodka&amp;rdquo; misspelled as &amp;ldquo;votka&amp;rdquo;&lt;/a&gt;. The Levenshtein distance is 1 but no trigrams match between the two. Since this is going to fail often (I don&amp;rsquo;t have any numbers for this but I think it&amp;rsquo;s a reasonable assumption that it&amp;rsquo;s significant) we&amp;rsquo;re going to have to keep looking.&lt;/p&gt;

&lt;h3 id=&#34;precomputed-levenshtein-index&#34;&gt;Precomputed Levenshtein Index&lt;/h3&gt;

&lt;p&gt;Since Levenshtein is the go-to measure of string similarity, it kind of makes sense to combine that with the concept of indexing. The question is how. We could pre-compute &amp;ldquo;Levenshtein variations&amp;rdquo; of words but that&amp;rsquo;s probably going to be zillions of words, right? Right. The problem here is edit distance encompasses all transpositions, insertions, deletions and replacements of letters in a word. For the &lt;a href=&#34;http://norvig.com/spell-correct.html&#34;&gt;English alphabet and a word 9 letters long, we&amp;rsquo;re looking at over 110,000 possible combinations&lt;/a&gt;. That&amp;rsquo;s bad enough but if we get into languages with larger alphabets, like Chinese, we&amp;rsquo;re talking absolutely enormous indexes.&lt;/p&gt;

&lt;p&gt;This is where I got stuck for a bit. I felt like I was on the right track but I didn&amp;rsquo;t know how to solve this particular issue. Then I found &lt;a href=&#34;http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/&#34;&gt;this blog post about a similar approach&lt;/a&gt; where they addressed the index size issue. Bingo! It&amp;rsquo;s always humbling when someone beats you to the punch but at the same time it&amp;rsquo;s nice to have a solution present itself.&lt;/p&gt;

&lt;p&gt;The basic concept here is instead of pre-calculating all possible Levenshtein variations of word, we only calculate the variations created by deleting letters from a word. The number of variations then is a number much smaller, for our purposes practically so. How does that work? How can we ignore insertions and everything else? The trick is to also calculate the deletion variants of our search term and then query each of those terms against our index. This is actually equivalent to querying a single term against a full Levenshtein index. For further reading, &lt;a href=&#34;http://fastss.csg.uzh.ch/&#34;&gt;a similar approach is described here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The stated way to calculate the number of variations is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;x = n for an edit distance of 1&lt;/li&gt;
&lt;li&gt;x = n * (n-1) / 2 for an edit distance of 2&lt;/li&gt;
&lt;li&gt;x = n! / d! / (n-d)! for edit distances &amp;gt; 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Where n is the length of the word and d is the edit distance. For our 9 letter word above, we&amp;rsquo;re looking at 45 combinations for the same edit distance. Much better than 110,000!&lt;/p&gt;

&lt;p&gt;For the record, the &lt;a href=&#34;http://blog.faroo.com/2012/06/07/improved-edit-distance-based-spelling-correction/&#34;&gt;above calculation&lt;/a&gt; isn&amp;rsquo;t 100% correct. Since we&amp;rsquo;re going to be discarding duplicate variations (of the same word) we&amp;rsquo;re going to end up with a smaller total number. Duplication happens when we have repeated letters in a word (the two l&amp;rsquo;s in &amp;ldquo;hello&amp;rdquo;) for example. That&amp;rsquo;s actually good news since the fewer terms we have in our index the better. It should be kept in mind however if trying to determine the total number of variations programmatically for some purpose, such as allocating memory.&lt;/p&gt;

&lt;h3 id=&#34;edit-distance&#34;&gt;Edit Distance&lt;/h3&gt;

&lt;p&gt;We should talk about edit distance for a moment. We&amp;rsquo;re going to want to find a &amp;ldquo;Goldilocks&amp;rdquo; edit distance &amp;ndash; one that gives us enough variations to be usable without generating an index that is too large to be practical. If you remember the note about trigrams above, you can guess that this magic number is going to be 3. When we&amp;rsquo;re dealing with the individual letters of a word, two seems to be too few (generates too many matches) and four seems to be too many (generates too few matches). In terms of handling misspellings we&amp;rsquo;re ok too. According to &lt;a href=&#34;http://norvig.com/spell-correct.html&#34;&gt;this informal study, over 98% of all spelling errors are within edit distance 2 or less&lt;/a&gt;. So we&amp;rsquo;re going to end up building our Levenshtein index with an edit distance of 3. Of course, since the universe is cruel, this will lead to its own problems.&lt;/p&gt;

&lt;h3 id=&#34;levenshtein-index-problem&#34;&gt;Levenshtein Index Problem&lt;/h3&gt;

&lt;p&gt;While this approach is robust it&amp;rsquo;s not without its own issues. Or, rather than blame the technique, let&amp;rsquo;s say that we expect too much of it. In a practical search engine (especially one that&amp;rsquo;s going to give suggestions on the fly) we&amp;rsquo;re likely going to want some form of prefix matching. That is, as we type &amp;ldquo;tre&amp;rdquo; we&amp;rsquo;re going to want to know if the word &amp;ldquo;trepidation&amp;rdquo; is in our search index (and in our documents). A Levenshtein edit distance of 3 is going to break down with words greater than length 6, since removing 3 letters from these words will never leave us with just the first 3 letters.&lt;/p&gt;

&lt;p&gt;One approach could be to store a separate prefix index along with our Levenshtein index (or, more likely, combined with). The problem with that, apart from the fact that it feels like a band-aid, is that it will break down if there&amp;rsquo;s a misspelling in the prefix. Again, not robust enough.&lt;/p&gt;

&lt;p&gt;Another approach would be to extend our edit distance to accommodate a three-letter prefix. That is, we&amp;rsquo;re going to calculate an edit distance, per word, of word length - 3. For our 9 letter word above, we&amp;rsquo;re going to calculate an edit distance of 6. Using our calculation above, we find that the number of combinations for edit distance 6 is 465. While that&amp;rsquo;s not too scary by itself, that&amp;rsquo;s an order of magnitude higher than an edit distance of 3. Multiply that by all of the words in our index and we&amp;rsquo;re going to end up with something too large to be practical.&lt;/p&gt;

&lt;p&gt;So, what can we do? I ended up using a what I consider to be a clever trick. Since we want to ensure that we&amp;rsquo;re storing the first three letters of every word, we can simply treat each word (over 6 letters) as two words. The first word is the entire word, regardless of the length. The second word is the first 6 letters of the word. We then combine these into one set (removing duplicates). While I&amp;rsquo;ve forgotten the exact increase in index size that I saw using this technique (IIRC it was around 30%), it was well within what&amp;rsquo;s acceptable for this application. In essence we&amp;rsquo;ve given higher weight to the beginning of the word. In practice we&amp;rsquo;re now going to be able to match &amp;ldquo;tre&amp;rdquo; against &amp;ldquo;trepidation&amp;rdquo; without having to use an edit distance as high as 8.&lt;/p&gt;

&lt;h3 id=&#34;storing-our-index-and-documents&#34;&gt;Storing Our Index and Documents&lt;/h3&gt;

&lt;p&gt;To index a set of documents using this technique, we&amp;rsquo;re actually going to have to create two indexes. The first index will be a list of our Levenshtein variations of a word that maps to a set of words, since a variation may map to more than one word at a time. The second index will be those words mapped to document ids. A third layer will be document ids to documents. We&amp;rsquo;re not going to call that an index, although since everything here is a set of a values mapped to keys, the distinction is arbitrary.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;aut -&amp;gt; [beautiful, flautist, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;beautiful -&amp;gt; [doc_1, doc_9, doc_31, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;doc_1 -&amp;gt; The beautiful girl rapidly typed on the screen of her phone &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we know how to generate our index, we need to think about storing it on disk. This is where LevelDB comes in. Again, LevelDB is a key value store. That&amp;rsquo;s as simple as a DB can get (and is what you&amp;rsquo;ll find under the hood of more complex databases). LevelDB allows us to store bytes by some manner of key, which are just more bytes. Like magic, it also allows us to retrieve bytes by a given key, provided it exists.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s not much point in going into the details of how LevelDB works now, but it&amp;rsquo;s an interesting topic. In short, LevelDB was written by some Googlers, loosely based on Google&amp;rsquo;s internet-scale BigTable. Although I&amp;rsquo;m not going to link benchmarks here, it&amp;rsquo;s fast, likely due to a combination of good design and simplicity. It&amp;rsquo;s an ideal fit for what we&amp;rsquo;re doing here, since we don&amp;rsquo;t need anything more complex than a key value store. So far our database is just three &amp;ldquo;tables&amp;rdquo;, a table that stores our documents and our indexes. Having said that, these aren&amp;rsquo;t actually tables as LevelDB has no concept of them.&lt;/p&gt;

&lt;p&gt;You could separate data by creating separate database instances, but it&amp;rsquo;s not required nor recommend to do so. What they do recommend is to add namespaces to keys so data with similar roles will be in contiguous blocks. That can be as simple as this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;000_aut -&amp;gt; [beautiful, flautist, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;li&gt;001_beautiful -&amp;gt; [doc_1, doc_9, doc_31, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;li&gt;002_doc_1 -&amp;gt; The beautiful girl rapidly typed on the screen of her phone &amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not only is LevelDB not a relational database, it&amp;rsquo;s not even a document-based database. That means if we want to store anything more complicated than a single value we&amp;rsquo;re going to have to serialize and deserialize the data ourselves. That may seem tedious but it does mean we can make sure we&amp;rsquo;re not wasting CPU cycles or disk space marshaling objects in a way that&amp;rsquo;s more complex than we actually need. We wanted something that&amp;rsquo;s close to the metal, so that&amp;rsquo;s what we&amp;rsquo;ve got. I won&amp;rsquo;t go into the details of what I did in this case other than to say that you&amp;rsquo;re likely to want to use some manner of delimited values. If you don&amp;rsquo;t want to go that low level, you could certainly use something like JSON or Google&amp;rsquo;s protocol buffers.&lt;/p&gt;

&lt;h3 id=&#34;querying-our-index&#34;&gt;Querying Our Index&lt;/h3&gt;

&lt;p&gt;Now that we&amp;rsquo;ve got our index and documents on disk, we can start querying them. Like was stated before, we&amp;rsquo;re going to need to calculate the Levenshtein variations of our search term (for an edit distance of up to 3) and then match each of those against our index. That means, yes, for a 9 letter word we&amp;rsquo;re going to have to hit the database 45 times. Luckily our database is fast and this is actually OK in practice. Also, most of our querying is going to happen with a 3 letter prefix, for which we&amp;rsquo;ll need to calculate an edit distance of zero (no variations) before testing our index. Similarly, a 4 letter term will only need an edit distance of one. In other words, our most common operations will have the least amount of complexity. A nine letter word is more towards the &amp;ldquo;worst case&amp;rdquo; end of the spectrum.&lt;/p&gt;

&lt;p&gt;So what do we get when we run the query? We get all words that contain our search term variations. A simple example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Search term &amp;ldquo;this&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Variations of search term: &amp;ldquo;this&amp;rdquo;, &amp;ldquo;his&amp;rdquo;, &amp;ldquo;tis&amp;rdquo;, &amp;ldquo;ths&amp;rdquo;, &amp;ldquo;thi&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;Words retrieved: &amp;ldquo;this&amp;rdquo;, &amp;ldquo;his&amp;rdquo;, &amp;ldquo;thine&amp;rdquo;, &amp;ldquo;history&amp;rdquo;, &amp;ldquo;thick&amp;rdquo;, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The members of the index we retrieve will look something like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;his -&amp;gt; [his, history, this, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;this -&amp;gt; [this, &amp;hellip;]&lt;/li&gt;
&lt;li&gt;thi -&amp;gt; [thick, this, &amp;hellip;]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you look at those results you&amp;rsquo;ll see something interesting: the word &amp;ldquo;this&amp;rdquo; is the most common word to appear on the right hand side. In fact, we can &amp;ndash; and will &amp;ndash; use that to rank our results. That won&amp;rsquo;t be the only way we score the results, but that will get us most of the way to determining what the intended word (exact match or not) most likely was.&lt;/p&gt;

&lt;h3 id=&#34;ranking-results&#34;&gt;Ranking Results&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Right hand side word count.&lt;/li&gt;
&lt;li&gt;Edit distance.&lt;/li&gt;
&lt;li&gt;Length of common prefix.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The edit distance in this case is the edit distance of the Levenshtein variation to the original indexed word. The length of the common prefix is unrelated to anything we&amp;rsquo;ve discussed so far. We calculate that by counting how many letters, starting from the beginning of the word, are shared between the Levenshtein variation and the original word. This allows us to give extra weight when scoring words that, you guessed it, share a common prefix. Again, using this was empirically arrived at as it&amp;rsquo;s more natural to rank words that have the same first few letters (or root) higher than others.&lt;/p&gt;

&lt;p&gt;I won&amp;rsquo;t go into details of how these individual elements are used to calculate word score. It&amp;rsquo;s not a secret or anything but I wouldn&amp;rsquo;t want to rob you of the joy of figuring it out (what works for your particular application) should you go down this road yourself. In a large, complicated topic, it&amp;rsquo;s one of the fun parts.&lt;/p&gt;

&lt;h3 id=&#34;ranking-documents&#34;&gt;Ranking Documents&lt;/h3&gt;

&lt;p&gt;Because writing a search engine is hard, this is only going to get us part of the way there. This will allow us to figure out which word(s) were most likely meant by our querying user (incorrect spelling or not) matched up to the documents that contain those words (again, regardless of spelling or variation). Now, we&amp;rsquo;re going to have to rank the resulting documents to determine which are most relevant to the query.&lt;/p&gt;

&lt;p&gt;I should also point out that we&amp;rsquo;re likely going to want to search for phrases instead of just single words. While I&amp;rsquo;m not going to directly address that here for the sake of brevity, the techniques we&amp;rsquo;re outlining here form the base that phrasal search can be built on.&lt;/p&gt;

&lt;p&gt;When we rank documents the first thing we&amp;rsquo;re likely to do is some form of counting term frequency. This is a whole topic unto itself but the end result is we&amp;rsquo;re most likely to end up calculating some form of tf-idf or term frequency-inverse document frequency. The basic idea here is that the more times a word appears in a document, the more relevant that document is to that word (from a query). But since that makes common but unimportant words rank very high (e.g., the word &amp;ldquo;the&amp;rdquo;) that frequency is penalized by how often the word appears across the set of all documents. Using td-idf we can rank documents relevant to the query &amp;ldquo;the automobile&amp;rdquo;, picking out those with &amp;ldquo;automobile&amp;rdquo; in them while ignoring documents with the word &amp;ldquo;the&amp;rdquo; in them.&lt;/p&gt;

&lt;h3 id=&#34;stop-words-canonicalization&#34;&gt;Stop Words, Canonicalization&lt;/h3&gt;

&lt;p&gt;Backing up a bit, it&amp;rsquo;s worth pointing out that ignoring unimportant words is a critical part of indexing and querying documents like we&amp;rsquo;re doing here. One of the most common ways of dealing with this is to use a list of so-called &amp;ldquo;stop words&amp;rdquo; to ignore words that aren&amp;rsquo;t considered relevant to a meaning of a document or a query. In English stop words will likely be articles, adverbs, etc and words that are rarely considered stop words will be proper nous, etc.&lt;/p&gt;

&lt;p&gt;Very closely related to this is a technique called stemming. Stemming is the process of canonicalizing groups of related words to a single form which makes searching more accurate (and reduces index complexity). An example would be the words &amp;ldquo;real&amp;rdquo; and &amp;ldquo;really&amp;rdquo; being mapped to the single word &amp;ldquo;real&amp;rdquo;. Since these words are closely related, it&amp;rsquo;s best to treat them as a single word. Again, that decreases the complexity of our index and also makes searching more robust, as searching for either &amp;ldquo;real&amp;rdquo; or &amp;ldquo;really&amp;rdquo; will bring up documents with either word in them. In English, it&amp;rsquo;s common to use a Porter Stemmer, which is an algorithm first conceived by, you guessed it, Porter, for reducing related English words to common forms.&lt;/p&gt;

&lt;p&gt;Now that we&amp;rsquo;ve gone over the use of stop words and stemming, we can go over why we&amp;rsquo;re not using either of these techniques here. The biggest problem with stop words is that they need to be managed per-language. For an application that should handle English as well as Chinese or Hebrew, it&amp;rsquo;s going to be a real pain to track down and manage word lists for all languages your application will likely encounter. There&amp;rsquo;s also the issue of language detection and documents containing more than one language.&lt;/p&gt;

&lt;p&gt;Similarly, stemming is language specific. Porter&amp;rsquo;s stemmer is English only. For each additional language we&amp;rsquo;re going to have to find another method, or skip it entirely. Of course, this type of canonicalization might not be needed for all languages, but the issue with language detection above still applies.&lt;/p&gt;

&lt;p&gt;Luckily, with our current design, we can just leave these things out. One of the additional benefit of our Levenshtein index is that it&amp;rsquo;s word form-agnostic. Along with dealing with spelling errors, we get matching of different word forms for free. Similarly, instead of directly dealing with stop words &amp;ndash; managing words by their importance relative to the meaning of our documents and queries, i.e, ranking documents by tf-idf, already accounts for this. In fact, although somewhat off topic, it&amp;rsquo;s entirely possible to generate lists of stop words (for any language) using tf-idf. In a sense, anything below a certain (arbitrary) tf-idf score is treated as a stop word.&lt;/p&gt;

&lt;h3 id=&#34;tf-idf&#34;&gt;TF-IDF&lt;/h3&gt;

&lt;p&gt;I won&amp;rsquo;t go into implementing tf-idf in too much detail other than showing one of the more common ways to calculate it. A common way to calculate tf-idf is the following form:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;tf(t) = how many times t appears in the document / total number of terms in the document&lt;/li&gt;
&lt;li&gt;idf(t) = log( total number of documents / number of docs containing term t )&lt;/li&gt;
&lt;li&gt;tfidf(t) = tf(t) * idf(t)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The use of the natural log in #2 is somewhat arbitrary and just one of the many weighting schemes used. This may have to be tuned to the application at hand. Although tf-idf is a workhorse metric, it&amp;rsquo;s interesting to note that there has yet to be a theoretical explanation for its effectiveness. It&amp;rsquo;s loosely associated with Zipf&amp;rsquo;s law but otherwise doesn&amp;rsquo;t have much in terms of a foundation, probabilistic or otherwise.&lt;/p&gt;

&lt;h3 id=&#34;closing-the-loop&#34;&gt;Closing the Loop&lt;/h3&gt;

&lt;p&gt;We can close the loop now. At a high level:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Calculate the Levenshtein variations of our search term (if needed).&lt;/li&gt;
&lt;li&gt;Check the first index for those term(s).&lt;/li&gt;
&lt;li&gt;Rank those terms for relevance, discarding those below a certain threshold.&lt;/li&gt;
&lt;li&gt;Match those terms to documents via the second (word) index.&lt;/li&gt;
&lt;li&gt;Rank those documents by td-idf, discarding those below a certain threshold.&lt;/li&gt;
&lt;li&gt;Present documents to user.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>First Five (and a Half) Minutes on a Server with a Shell Script</title>
      <link>http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-a-shell-script/</link>
      <pubDate>Wed, 29 Oct 2014 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-a-shell-script/</guid>
      <description>

&lt;p&gt;About a year ago I wrote &lt;a href=&#34;http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-ansible&#34;&gt;this&lt;/a&gt; about hardening a fresh server using Ansible. This post has received about 10x as much traffic as anything else I&amp;rsquo;ve written. Oddly, admin is the area I&amp;rsquo;m probably least knowledgable about when it comes to software.&lt;/p&gt;

&lt;p&gt;Anyway, the Ansible script I wrote about in that post is out of date. I realized this recently after trying to use it on a fresh install. I went about updating it (Ansible has made some breaking changes since then) and came to the realization that it would be faster and easier to just write a shell script.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s not to say Ansible (and tools like it) don&amp;rsquo;t have their place. They obviously do. But for one-off installs or occasional use the learning curve is too steep. It&amp;rsquo;s much easier to stay current with shell scripting than it is to stay current with a tool that is constantly being changed (improved) and meant for administering very large installations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Note: This is for the Ubunutu 10.04 x64 image available on Digital Ocean
# and may not work for other images / OS versions.

# Warning: This script directy edits some configuration files that may
# render your OS unusable if there is an error. Use at your own risk.

useradd deploy
mkdir /home/deploy
mkdir /home/deploy/.ssh
chmod 700 /home/deploy/.ssh
chsh -s /bin/bash deploy
cp .bashrc .profile /home/deploy

cp /root/.ssh/authorized_keys /home/deploy/.ssh/authorized_keys
chmod 400 /home/deploy/.ssh/authorized_keys
chown deploy:deploy /home/deploy -R

echo &amp;quot;Set password for user deploy&amp;quot;
passwd deploy

apt-get update
apt-get upgrade -y
apt-get install fail2ban mosh ufw vim unattended-upgrades -y

cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/sudoers
Defaults        env_reset
Defaults        mail_badpass
Defaults        secure_path=&amp;quot;/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&amp;quot;

root    ALL=(ALL:ALL) ALL
deploy  ALL=(ALL:ALL) ALL
EOF

cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/ssh/sshd_config
Port 22
Protocol 2
HostKey /etc/ssh/ssh_host_rsa_key
HostKey /etc/ssh/ssh_host_dsa_key
HostKey /etc/ssh/ssh_host_ecdsa_key
HostKey /etc/ssh/ssh_host_ed25519_key
UsePrivilegeSeparation yes
KeyRegenerationInterval 3600
ServerKeyBits 1024
SyslogFacility AUTH
LogLevel INFO
LoginGraceTime 120
PermitRootLogin no
StrictModes yes
RSAAuthentication yes
PubkeyAuthentication yes
IgnoreRhosts yes
RhostsRSAAuthentication no
HostbasedAuthentication no
PermitEmptyPasswords no
ChallengeResponseAuthentication no
PasswordAuthentication no
X11Forwarding yes
X11DisplayOffset 10
PrintMotd no
PrintLastLog yes
TCPKeepAlive yes
AcceptEnv LANG LC_*
Subsystem sftp /usr/lib/openssh/sftp-server
UsePAM yes
EOF

service ssh restart

ufw allow 22
ufw allow 80
ufw allow 443
ufw allow 60000:61000/udp
ufw --force enable

cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/apt/apt.conf.d/10periodic
APT::Periodic::Update-Package-Lists &amp;quot;1&amp;quot;;
APT::Periodic::Download-Upgradeable-Packages &amp;quot;1&amp;quot;;
APT::Periodic::AutocleanInterval &amp;quot;7&amp;quot;;
APT::Periodic::Unattended-Upgrade &amp;quot;1&amp;quot;;
EOF

cat &amp;lt;&amp;lt; EOF &amp;gt; /etc/apt/apt.conf.d/50unattended-upgrades 
Unattended-Upgrade::Allowed-Origins {
    &amp;quot;Ubuntu lucid-security&amp;quot;;
};
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ve stripped this down a bit from the original version. Logwatch, in particular, seemed more annoying than useful. You may or may not want to install that yourself.&lt;/p&gt;

&lt;h3 id=&#34;danger&#34;&gt;Danger&lt;/h3&gt;

&lt;p&gt;A couple of notes about using this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This script does two things that when combined can render your instance unusable: It creates a new user and password and disallows ssh from logging in as root. If something goes wrong with the creation of the new user you&amp;rsquo;ll be locked out and / or won&amp;rsquo;t be able to make any root-level changes.&lt;/li&gt;
&lt;li&gt;Also in the potentially unusable category: This script overwrites your /etc/sudoers file. If anything goes wrong here you&amp;rsquo;ll probably have to start over from scratch.&lt;/li&gt;
&lt;li&gt;The script isn&amp;rsquo;t idempotent. For all practical purposes, the individual actions are idempotent, but you should be aware of that.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In other words, only run this on a fresh install and be prepared to have to start over from scratch if anything goes wrong.&lt;/p&gt;

&lt;h3 id=&#34;simple-fast&#34;&gt;Simple, Fast&lt;/h3&gt;

&lt;p&gt;The upside to using this is it&amp;rsquo;s easy to change with only basic shell scripting knowledge and it&amp;rsquo;s faster than Ansible to run. Much faster actually. Having said that, Ansible may have made improvements in speed since I used it last.&lt;/p&gt;

&lt;p&gt;To actually run it, just run the following commands:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl https://gist.githubusercontent.com/lattejed/5047d9f85896b8946c7d/raw/e3534c6ac5248ad7bc711c053fec45c22441c87a/gistfile1.sh &amp;gt; secure_ubuntu_10.04_x64.sh
scp secure_ubuntu_10.04_x64.sh root@&amp;lt;ip_address or host&amp;gt;:/root/
ssh root@&amp;lt;ip_address or host&amp;gt; chmod +x secure_ubuntu_10.04_x64.sh
ssh root@&amp;lt;ip_address or host&amp;gt; ./secure_ubuntu_10.04_x64.sh
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>That ToDo App you Always Wanted</title>
      <link>http://lattejed.com/pages/that-todo-app-you-always-wanted/</link>
      <pubDate>Tue, 21 Oct 2014 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/that-todo-app-you-always-wanted/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Note: This was originally titled: A Simple ToDo App in Swift&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;I decided the best way to learn Swift would be to whip together a simple Core Data app with a single view controller. That gives us a project with some depth but doesn&amp;rsquo;t waste too much time on breadth by minimizing the time spent in IB and wiring up UI components. A ToDo app seemed like an obvious choice.&lt;/p&gt;

&lt;p&gt;Our project requirements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Persist todos (Core Data)&lt;/li&gt;
&lt;li&gt;Have a completed state for todos, be able to delete them&lt;/li&gt;
&lt;li&gt;Have custom swipe controls for marking complete, deleting&lt;/li&gt;
&lt;li&gt;Edit todos in-place and touch to edit&lt;/li&gt;
&lt;li&gt;Color todos by position in list (urgency)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This project started with the navigation controller template in Xcode. I won&amp;rsquo;t go over all of the changes or inclusions but you can get a &lt;a href=&#34;https://github.com/lattejed/Swift-ToDo&#34;&gt;complete copy here&lt;/a&gt; if you&amp;rsquo;re interested. I also won&amp;rsquo;t go through the building of the app step-by-step instead I&amp;rsquo;ll just cover some of the more interesting parts with regards to transitioning to Swift.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://lattejed.com/img/Swift-ToDo_screencast.gif&#34; alt=&#34;To-Do App&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;subclassing-nsmanagedobject&#34;&gt;Subclassing NSManagedObject&lt;/h3&gt;

&lt;p&gt;This seems even more straightforward in Swift than it did in Objective-C, mostly because the former is more terse. There&amp;rsquo;s some debate about whether or not to use Xcode generated NSManagedObject subclasses, use a tool like mogenerator or write the classes by hand. After having worked on large projects with mogenerator I can say I&amp;rsquo;m not really a fan of the &amp;ldquo;two-class&amp;rdquo; approach. It adds a lot of bloat the project and doesn&amp;rsquo;t really gain you that much. Swift makes subclassing by hand very easy. This is our &lt;code&gt;ToDo&lt;/code&gt; model:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;import CoreData

class ToDo: NSManagedObject {
   
    @NSManaged
    var createdAt: NSDate
    
    @NSManaged
    var summary: String?
    
    @NSManaged
    var order: Int32
    
    @NSManaged
    var completed: Bool
    
    class func entityName() -&amp;gt; NSString {
        return &amp;quot;ToDo&amp;quot;
    }
    
    class func insertNewObjectIntoContext(context : NSManagedObjectContext) -&amp;gt; ToDo {
        let todo = NSEntityDescription.insertNewObjectForEntityForName( self.entityName(), inManagedObjectContext:context ) as ToDo;
        todo.createdAt = NSDate();
        todo.order = todo.lastMaxPosition() + 1
        todo.completed = false
        return todo;
    }
    
    func lastMaxPosition () -&amp;gt; Int32 {
        let request = NSFetchRequest(entityName: self.entity.name!)
        request.fetchLimit = 1
        request.sortDescriptors = [NSSortDescriptor(key: &amp;quot;order&amp;quot;, ascending: false)]
        
        var error: NSError? = nil
        let context : NSManagedObjectContext = self.managedObjectContext!
        let todos = context.executeFetchRequest(request, error: &amp;amp;error) as [ToDo]
        return todos.isEmpty ? 0 : todos[0].order
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This of course assumes we&amp;rsquo;ve set up a model with the same parameters and types. One possible stumbling blocks setting up the model is that entities in the model have to be given classes prefixed by the module. In other words the class setting in Xcode for Objective-C would have been &lt;code&gt;ToDo&lt;/code&gt; whereas under swift it has to be &lt;code&gt;&amp;lt;xcdatamodeld name&amp;gt;.ToDo&lt;/code&gt;, e.g., &lt;code&gt;Swift_ToDo.ToDo&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You can see we&amp;rsquo;ve added the factory method &lt;code&gt;insertNewObjectIntoContext&lt;/code&gt;. This is a convenience and also allows us to set up some default values. Some people prefer using NSManagedObjects &lt;code&gt;awakeFromInsert&lt;/code&gt; for this but personally I&amp;rsquo;ve never seen the point. They both are called once in the object&amp;rsquo;s lifetime and both give the same results. You can see we&amp;rsquo;ve also added the method &lt;code&gt;lastMaxPosition&lt;/code&gt;. This allows us to fetch the last maximum order number when we create a new object. This has the effect of putting new objects at the top of the sort order. Why the explicit sort order?&lt;/p&gt;

&lt;h3 id=&#34;moving-uitableview-rows-using-nsfetchedresultscontroller&#34;&gt;Moving UITableView Rows Using NSFetchedResultsController&lt;/h3&gt;

&lt;p&gt;This is not specific to Swift. When you&amp;rsquo;re rearranging rows with NSFetchedResultsController you&amp;rsquo;ll have to bandage a few methods as well as set an explicit sort order for the records. Setting an explicit sort order in a database is a large topic since setting a sort order on one record inevitably means setting the sort order on other, possibly all, records. If you have a large database then this could be an expensive operation. Since we&amp;rsquo;re not likely to be dealing with large numbers of todo items in this app, we can take a fairly naive approach.&lt;/p&gt;

&lt;p&gt;To set the sort order of a new record we use the method mentioned above and fetch the current first item in the list. To make this insert less expensive, we order the list backwards. When we add a new item the sort order becomes &lt;code&gt;last sort order + 1&lt;/code&gt;. That&amp;rsquo;s simple enough but when we&amp;rsquo;re reordering rows things get a little more complicated. Again, since we&amp;rsquo;re likely to be dealing with a small number of items, we&amp;rsquo;ll simply reorder every record when we have to move a row.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;// UITableViewDataSource

var isMovingItem : Bool = false

override func tableView(tableView: UITableView, canMoveRowAtIndexPath indexPath: NSIndexPath) -&amp;gt; Bool {
    return true
}

override func tableView(tableView: UITableView, moveRowAtIndexPath sourceIndexPath: NSIndexPath, toIndexPath destinationIndexPath: NSIndexPath) {
    isMovingItem = true
    
    if var todos = self.fetchedResultsController.fetchedObjects? {
        let todo = todos[sourceIndexPath.row] as ToDo
        todos.removeAtIndex(sourceIndexPath.row)
        todos.insert(todo, atIndex: destinationIndexPath.row)
        
        var idx : Int32 = Int32(todos.count)
        for todo in todos as [ToDo] {
            todo.order = idx--
        }
        saveContext()
    }
    
    dispatch_async(dispatch_get_main_queue(), { () -&amp;gt; Void in
        tableView.reloadRowsAtIndexPaths( tableView.indexPathsForVisibleRows()!, withRowAnimation: UITableViewRowAnimation.Fade )
    })
    
    isMovingItem = false
}

// NSFetchedResultsControllerDelegate

func controllerWillChangeContent(controller: NSFetchedResultsController) {
    if isMovingItem {
        return
    }
    self.tableView.beginUpdates()
}

func controller(controller: NSFetchedResultsController, didChangeSection sectionInfo: NSFetchedResultsSectionInfo, atIndex sectionIndex: Int, forChangeType type: NSFetchedResultsChangeType) {
    if isMovingItem {
        return
    }
    // Code removed
}

func controller(controller: NSFetchedResultsController, didChangeObject anObject: AnyObject, atIndexPath indexPath: NSIndexPath?, forChangeType type: NSFetchedResultsChangeType, newIndexPath: NSIndexPath?) {
    if isMovingItem {
        return
    }
    // Code removed
}

func controllerDidChangeContent(controller: NSFetchedResultsController) {
    if isMovingItem {
        return
    }
    self.tableView.endUpdates()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the &lt;code&gt;moveRowAtIndexPath&lt;/code&gt; method we copy the fetched results controller&amp;rsquo;s objects to a mutable array and the set the sort order of each record starting from the number of records and working our way down to one.&lt;/p&gt;

&lt;p&gt;You may be wondering what the &lt;code&gt;dispatch_async&lt;/code&gt; call is doing in there. The internal state of the table view is in disarray until after that method returns. That means if we try to reload our rows before that method returns, we&amp;rsquo;ll get unpredictable results (like reorder controls missing, reordered rows getting &amp;ldquo;stuck&amp;rdquo;, etc). While using &lt;code&gt;dispatch_async&lt;/code&gt; this way has always felt kind of like a hack, it is a simple way to move an operation to the back of the main queue, bypassing the issue.&lt;/p&gt;

&lt;p&gt;To move the item, we have to keep a Bool property &lt;code&gt;isMovingItem&lt;/code&gt; and set it while we&amp;rsquo;re moving the record. We&amp;rsquo;ll then check that in the controller&amp;rsquo;s &lt;code&gt;controller*&lt;/code&gt; methods and bail out if we are in the middle of a move as those methods will get called and throw exceptions when they&amp;rsquo;re not supposed to. This highlights the problem with convenience classes like NSFetchedResultsController &amp;ndash; if you&amp;rsquo;re going to make managing a table view a black box like this, you really have to go all of the way with it.&lt;/p&gt;

&lt;h3 id=&#34;adding-closures-to-uialertview&#34;&gt;Adding Closures to UIAlertView&lt;/h3&gt;

&lt;p&gt;Objective-C&amp;rsquo;s blocks, combined with categories, allowed for streamlining a lot of UIKit classes by replacing delegation with block-based callbacks. The typical way to do this was to combine a category with a helper object that would act as a delegate. As categories could not contain instance variables, the solution was to use the Objecitve-C runtime&amp;rsquo;s &lt;code&gt;objc_setAssociatedObject&lt;/code&gt; and &lt;code&gt;objc_getAssociatedObject&lt;/code&gt; to attach the helper object to the object. The helper object is then tied to the lifetime of the object and all is well.&lt;/p&gt;

&lt;p&gt;So can we do this in Swift? &lt;a href=&#34;http://www.russbishop.net/swift-storage-for-extension-properties&#34;&gt;Yes, you can&lt;/a&gt;. Instead of using categories we use a class extension. Since extensions cannot store data, we have to use the helper object and, surprisingly, the Objective-C runtime. It turns out it&amp;rsquo;s straightforward to adapt the original method to Swift with only minor changes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-swift&#34;&gt;import Foundation
import UIKit

class AlertViewHelper {
    typealias ActionSheetFinished = (alertView: UIAlertView) -&amp;gt; ()
    var finished: ActionSheetFinished
    init(finished: ActionSheetFinished) {
        self.finished = finished
    }
}

private let _helperClassKey = malloc(4)

extension UIAlertView: UIAlertViewDelegate {

    private var helperObject: AlertViewHelper? {
        get {
            let r : AnyObject! = objc_getAssociatedObject(self, _helperClassKey)
            return r as? AlertViewHelper
        }
        set {
            objc_setAssociatedObject(self, _helperClassKey, newValue, UInt(OBJC_ASSOCIATION_RETAIN_NONATOMIC));
        }
    }
    
    convenience init(title: String, message: String, cancelButtonTitle: String?, firstButtonTitle: String, finished:(alertView: UIAlertView) -&amp;gt; ()) {
        self.init(title: title, message: message, delegate: nil, cancelButtonTitle: cancelButtonTitle, otherButtonTitles: firstButtonTitle)
        self.delegate = self
        self.helperObject = AlertViewHelper(finished: finished)
    }
    
    public func alertView(alertView: UIAlertView, clickedButtonAtIndex buttonIndex: Int) {
        if buttonIndex == 1 {
            self.helperObject?.finished(alertView: self)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case we&amp;rsquo;re storing the callback closure in the helper object and the UIAlertView is acting as its own delegate. You could make the helper object the delegate as well if you&amp;rsquo;re not happy about making an object its own delegate.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re wondering what the &lt;code&gt;malloc&lt;/code&gt; call is for we&amp;rsquo;re simply creating a pointer address which we&amp;rsquo;ll use to get and set the helper object. I&amp;rsquo;m not 100% sure how I feel about this since it doesn&amp;rsquo;t feel like idiomatic Swift. I&amp;rsquo;ve read that storage may be added to extensions in the future. If that&amp;rsquo;s true, then we could skip calling the Objective-C runtime in this manner.&lt;/p&gt;

&lt;p&gt;Once this is done we can use a UIAlertView to prompt users to delete todos. Instead of setting up a delegate method and extra properties to do this within the view controller, we can wrap everything up in a closure.&lt;/p&gt;

&lt;h3 id=&#34;passing-swift-dictionaries-to-objective-c-classes&#34;&gt;Passing Swift Dictionaries to Objective-C Classes&lt;/h3&gt;

&lt;p&gt;This was something that&amp;rsquo;s not very obvious at first and can lead to numerous hard to understand type errors. If you look at the type of the parameter in question, you&amp;rsquo;ll see that it&amp;rsquo;s &lt;code&gt;[NSObject : AnyObject]?&lt;/code&gt;. This is the Swift type of an NSDictionary. If you define a dictionary with this type (seems obvious right?) you&amp;rsquo;ll run into numerous type errors. The proper way to do it is to define you dictionary as &lt;code&gt;Dictionary&amp;lt;NSObject, AnyObject&amp;gt;&lt;/code&gt;. When you pass it as a parameter, it will automatically be bridged to an NSDictionary. While this is obvious in retrospect, the documentation is vague.&lt;/p&gt;

&lt;h3 id=&#34;handling-iphone-6-and-6-screen-sizes&#34;&gt;Handling iPhone 6 and 6+ Screen Sizes&lt;/h3&gt;

&lt;p&gt;Happily there&amp;rsquo;s not much to worry about here (assuming you&amp;rsquo;re supporting 7.x and 8.x only) apart from setting up the proper constraints in IB. This is admittedly a very simple app but I found the different screens sizes handled without issue.&lt;/p&gt;

&lt;h3 id=&#34;misc-objective-c-and-swift-observations&#34;&gt;Misc Objective-C and Swift Observations&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Closure syntax seems to be actually worse than block syntax. Wow.&lt;/li&gt;
&lt;li&gt;Swift seems to have a much better type system than Objective-C, yet selectors are stringly typed?&lt;/li&gt;
&lt;li&gt;No header files. What a relief not having to type things twice.&lt;/li&gt;
&lt;li&gt;Swift is succinct and has a good type system. I&amp;rsquo;m confident it will live up to its hype of being a productive language.&lt;/li&gt;
&lt;li&gt;If you&amp;rsquo;re missing &lt;code&gt;#pragma mark -&lt;/code&gt; to divide up large classes, don&amp;rsquo;t worry, you can use &lt;code&gt;// MARK:&lt;/code&gt; to the same effect.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>[Ab]using Blocks for Cleaner MVC in Obj-C</title>
      <link>http://lattejed.com/pages/abusing-blocks-for-cleaner-mvc-in-obj-c/</link>
      <pubDate>Mon, 26 May 2014 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/abusing-blocks-for-cleaner-mvc-in-obj-c/</guid>
      <description>&lt;p&gt;As I&amp;rsquo;ve started to utilize blocks more in iOS/OS X development I&amp;rsquo;ve noticed a patter emerge and wanted to talk about it. It&amp;rsquo;s using the same building blocks (excuse the pun) are you&amp;rsquo;re likely to find in any Cocoa project but leveraging blocks to the fullest extent has sped up development time for me and led to both thin controllers (which I think are good) and a very strict separation between the different layers in MVC.&lt;/p&gt;

&lt;p&gt;(Note: I wanted to point out that MVC in Cocoa in general, and explicitly in the example I give here, is more accurately called Model-View-Adapter as the model and view layers do not interact directly with one another, as they would be allowed to do in traditional MVC.)&lt;/p&gt;

&lt;p&gt;I won&amp;rsquo;t talk about blocks since they&amp;rsquo;ve been around for a while but if you&amp;rsquo;re not familiar with Obj-C a block is an anonymous / first class function. It grants Obj-C (and C and C++) a handy tool for adopting a more functional programming style. The syntax can be awkward at first and I recommend &lt;a href=&#34;http://fuckingblocksyntax.com/&#34;&gt;this site&lt;/a&gt; as a handy reference and for an occasional laugh.&lt;/p&gt;

&lt;p&gt;So what does a block have to do with MVC? In MVC the controller layer is responsible for mediating between the model and view layers and usually &amp;ldquo;owns&amp;rdquo; or manages the lifecycle of both. While in theory a controller will generally be &amp;ldquo;thin&amp;rdquo;, doing no more than it has to do to tie model to view, they tend to bloat over time.&lt;/p&gt;

&lt;p&gt;In very practical terms, controllers usually have a lot of functions defined in them. For every possible action in a view layer the controller will usually have a separate function (or a shared function with additional logic to determine the sender and action required). Working with Xcode and IB, that means defining and implementing a function as well as making a connection for that action in IB. Since we usually need a reference to the sender(s) (think a set of buttons with mutually exclusive state) we also end up defining properties. That&amp;rsquo;s a lot of &amp;ldquo;stuff&amp;rdquo; for, say, an &amp;ldquo;Open File&amp;rdquo; button.&lt;/p&gt;

&lt;p&gt;So the first step in cleaning up our controller is adding blocks to buttons that allow us to define that button&amp;rsquo;s action. We can do this quite easily by using the Obj-C runtime together with a category:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;//
//  NSButton+LJBlocks.h
//
//  Created by Matthew Smith on 4/21/14.
//  Copyright (c) 2014 LatteJed. All rights reserved.
//

#import &amp;lt;Cocoa/Cocoa.h&amp;gt;

@interface NSButton (LJBlocks)

- (void)setActionBlock:(void (^)(void))block;

@end

//
//  NSButton+LJBlocks.m
//
//  Created by Matthew Smith on 4/21/14.
//  Copyright (c) 2014 LatteJed. All rights reserved.
//

#import &amp;quot;NSButton+LJBlocks.h&amp;quot;
#import &amp;lt;objc/runtime.h&amp;gt;

static void* const kNSButton_LJBlocks_HelperKey = (void *)&amp;amp;kNSButton_LJBlocks_HelperKey;

@interface __NSButtonHelper : NSObject

@property (nonatomic, weak) NSButton* owner;
@property (nonatomic, copy) void (^block)(void);

- (void)action:(id)sender;

@end

@implementation NSButton (LJBlocks)

- (void)setActionBlock:(void (^)(void))block;
{
    __NSButtonHelper* helper = [self lj_NSPopupButton_blocks_helper];
    helper.block = block;
    
    [self setAction:@selector(action:)];
    [self setTarget:helper];
}

- (__NSButtonHelper *)lj_NSPopupButton_blocks_helper;
{
    __NSButtonHelper* helper = objc_getAssociatedObject(self, kNSButton_LJBlocks_HelperKey);
    if (!helper)
    {
        helper = [__NSButtonHelper new];
        helper.owner = self;
        objc_setAssociatedObject(self, kNSButton_LJBlocks_HelperKey, helper, OBJC_ASSOCIATION_RETAIN_NONATOMIC);
    }
    return helper;
}

@end

@implementation __NSButtonHelper

- (void)action:(id)sender;
{
    if (self.owner)
    {
        self.block();
    }
}

@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a very useful pattern. Here we&amp;rsquo;re creating a category with a single method that allows us to add a block that will get called whenever the button is pressed. Since controls in Cocoa need a target and an action (an object and a method) we use what&amp;rsquo;s called a glue object (or trampoline or helper) that gets created when the block is set. To hide this from the user, we have the control retain the helper object using the runtime method &lt;code&gt;objc_setAssociatedObject&lt;/code&gt;. (This is a common workaround to a category&amp;rsquo;s inability to define instance variables.)&lt;/p&gt;

&lt;p&gt;What this means in practice is that we can minimize the &amp;ldquo;glue&amp;rdquo; we need to connect our button to our controller. Instead of defining a method and a property we can simply define a property. Instead of spreading out our logic through the controller, we can define our method anonymously in an appropriate initialization method (most likely &lt;code&gt;awakeFromNib&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;To complement this functional controller style I tend to post notifications from the model and then set up observers in the controller also using blocks. This is much easier to show than explain. Here is our model:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;//
//  Model.h
//
//  Created by Matthew Smith on 5/21/14.
//  Copyright (c) 2014 LatteJed. All rights reserved.
//

static NSString* const kNotificationURLDidUpdate = @&amp;quot;kNotificationURLDidUpdate&amp;quot;;

@interface Model : NSObject

@property (nonatomic, copy) NSURL* url;

@end

//
//  Model.m
//
//  Created by Matthew Smith on 5/21/14.
//  Copyright (c) 2014 LatteJed. All rights reserved.
//

#import &amp;quot;Model.h&amp;quot;

@implementation Model

- (void)setUrl:(NSURL *)url;
{
    _url = url;
    [[NSNotificationCenter defaultCenter] postNotificationName:kNotificationURLDidUpdate
                                                        object:self];
}

@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is simplified to only contain one property, the url of some file. We use a custom setter to post a notification after a url has been set. Our controller would then look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-objectivec&#34;&gt;//
//  Controller.m
//
//  Created by Matthew Smith on 4/21/14.
//  Copyright (c) 2014 LatteJed. All rights reserved.
//

#import &amp;quot;Controller.h&amp;quot;
#import &amp;quot;Model.h&amp;quot;

@interface Controller ()

@property (nonatomic, weak) IBOutlet NSButton* openFileButton;
@property (nonatomic, weak) IBOutlet FileView* fileView;
@property (nonatomic, strong) Model* model;

@end

@implementation Controller

- (void)awakeFromNib;
{
    [self.openFileButton setActionBlock:^{
        NSOpenPanel *panel = [NSOpenPanel openPanel];
        [panel beginSheetModalForWindow:[[self view] window]
                      completionHandler:^(NSInteger result) {
                          if (result == NSFileHandlingPanelOKButton)
                          {
                              self.model = [Model new];
                              self.model.url = [[panel URLs] firstObject];
                          }
                      }];
    }];
    
    [[NSNotificationCenter defaultCenter] 
              addObserverForName:kNotificationURLDidUpdate
                          object:nil
                           queue:nil
                      usingBlock:^(NSNotification *note) {
                          if ([self.model url])
                          {
                              [self.fileView setFileWithURL:self.model.url];
                          }
                      }];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can see that the entire MVC relationship here is defined by two blocks: the block provided by the button that gets called when it&amp;rsquo;s pressed, which updates the model (in this case after the file dialog returns successfully), and the block provided by the notification observer. Although it would be possible to &amp;ldquo;short cut&amp;rdquo; the update to the view by having the controller update the view directly, I find this to be conceptually much cleaner and makes situations where the model is driving (and not user interaction) easier to deal with. Again, this also saves us from having to define additional methods on the controller, which means less typing.&lt;/p&gt;

&lt;p&gt;While a trivial example like this seems, well, trivial, if we add in a set of buttons (say zoom in and zoom out buttons) we now have to deal with lots of additional logic and edge cases for what should be a simple operation. We can have the model define an initial zoom level when it&amp;rsquo;s created and cascade that to the controller (where we can disable/enable buttons appropriately) and view. We can have the controller validate input (can we zoom in any further?) and have a single point of action for everything we need to do.&lt;/p&gt;

&lt;p&gt;This is pretty simple, so why bother?&lt;/p&gt;

&lt;p&gt;I think this is valuable for a number of reasons. It lends conceptual consistency for how a controller operates &amp;ndash; everything cascades from the model and everything is handled in an anonymous function &amp;ndash; the controller is simpler and its role of &amp;ldquo;mediating&amp;rdquo; more clearly defined. I also find that it makes it harder to break the rules of MVC (something I do occasionally even though I have quite a bit of experience) which saves refactoring time later.&lt;/p&gt;

&lt;p&gt;Another reason is that although controllers should be thin logically, in practice they end up handling a lot of interaction between the view and model layers, which means they end up bloated with dozens of methods, &lt;code&gt;#pragma mark -&lt;/code&gt; sections, delegate method implementations, etc. Using primarily anonymous functions for this mediation makes controller code more succinct and manageable.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First Five (and a Half) Minutes on a Server with Ansible</title>
      <link>http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-ansible/</link>
      <pubDate>Tue, 03 Sep 2013 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-ansible/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Note: The Ansible script below is unusable due to breaking changes. I&amp;rsquo;ve written about a similar approach &lt;a href=&#34;http://lattejed.com/pages/first-five-and-a-half-minutes-on-a-server-with-a-shell-script&#34;&gt;here&lt;/a&gt; using a simple shell script&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is a response/addendum to two really good &amp;ldquo;first five minutes&amp;rdquo; style posts discussing the setting up and basic hardening of a remote server. Brian Kennedy discusses his first five minutes here&lt;sup&gt;1&lt;/sup&gt; on Ubuntu. It&amp;rsquo;s a great tutorial covering the basics of security. Of course, if you&amp;rsquo;ve gone through it once you&amp;rsquo;ll want to automate it. There is also a post on automating the process&lt;sup&gt;2&lt;/sup&gt; (actually using the steps described in Brian&amp;rsquo;s post) with Ansible. The latter was either not tested or only worked on earlier version of Ubuntu/Ansible. I&amp;rsquo;ll cover an updated version here that works with the most recent version of Ansible and Ubuntu 13.04 x64 and includes some helpful additions.&lt;/p&gt;

&lt;p&gt;So, starting from a virgin install of Ubuntu server we&amp;rsquo;re going to want to perform the following steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Update &amp;amp; upgrade the system via apt-get&lt;/li&gt;
&lt;li&gt;Install vim &amp;amp; mosh (personal preferences)&lt;/li&gt;
&lt;li&gt;Install fail2ban to block ssh brute-force attempts&lt;/li&gt;
&lt;li&gt;Reset our root password to something strong&lt;/li&gt;
&lt;li&gt;Create a new user so we don&amp;rsquo;t have to use root&lt;/li&gt;
&lt;li&gt;Copy over our pub key&lt;/li&gt;
&lt;li&gt;Lock down sudo&lt;/li&gt;
&lt;li&gt;Lock down ssh to prevent root &amp;amp; password login&lt;/li&gt;
&lt;li&gt;Setup the ufw firewall&lt;/li&gt;
&lt;li&gt;Configure unattended security upgrades&lt;/li&gt;
&lt;li&gt;Configure logwatch to email daily server logs&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Even if you can do all of that in five minutes, this is obviously complicated enough that we want an automation tool to handle it. After reviewing popular automation tools like Chef and Puppet, I decided to go with the slightly lesser known and arguably simpler Ansible. Ansible is simpler because it doesn&amp;rsquo;t require any server side installs to work. All Ansible commands are run via ssh from your computer and only need a password or private key to run. Ansible commands are organized in &amp;ldquo;playbooks&amp;rdquo; and Ansible has a extensive set of modules that simplify common tasks.&lt;/p&gt;

&lt;p&gt;Installing Ansible is easy (here for OS X 10.8.x):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone git://github.com/ansible/ansible.git
cd ./ansible
sudo make install

sudo easy_install jinja2
sudo easy_install pyyaml
sudo easy_install paramiko

source ./hacking/env-setup

ssh-agent bash
ssh-add ~/.ssh/id_rsa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This assumes the following: You&amp;rsquo;re running OS X with Python installed and you&amp;rsquo;ve already setup a public/private keypair on your machine. This also assumes that you&amp;rsquo;ve pre-installed your public key on the server. I&amp;rsquo;m using DigitalOcean which allows you to setup your public key ahead of time. If memory serves AWS does as well. If not, you&amp;rsquo;ll have to check the Ansible docs on passing a password to the server when you run the playbook.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s make sure Ansible is working properly:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;echo &amp;quot;&amp;quot; &amp;gt; host.ini
ansible all -i host.ini -m ping -u root
# x.x.x.x | success &amp;gt;&amp;gt; {
#    &amp;quot;changed&amp;quot;: false,
#    &amp;quot;ping&amp;quot;: &amp;quot;pong&amp;quot;
# }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You should get a &amp;ldquo;pong&amp;rdquo; as a result. If not, check the Ansible docs for installation and configuration.&lt;/p&gt;

&lt;p&gt;Now that we&amp;rsquo;re setup, we need to create a playbook to run the steps outlined above. I&amp;rsquo;ll give it here in its entirety and then go over some of the more important bits:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;---
- hosts: newservers
  vars:
  - ubuntu_release: raring
  - logwatch_email: 
    # crypted passwords, generated on a Linux box using: 
    # echo &#39;import crypt,getpass; print crypt.crypt(getpass.getpass(), &amp;quot;$6$YOURSALT&amp;quot;)&#39; | python -
  - root_password: &#39;&#39;
  - deploy_password: &#39;&#39;


  tasks:
  - name: Change root password
    action: user name=root password=$root_password

  - name: Update APT package cache
    action: apt update_cache=yes

  - name: Upgrade APT to the lastest packages
    action: apt upgrade=safe

  - name: Install mosh
    action: apt pkg=mosh state=installed

  - name: Install vim
    action: apt pkg=vim state=installed

  - name: Install fail2ban
    action: apt pkg=fail2ban state=installed

  - name: Add deployment user
    action: user name=deploy password=$deploy_password

  - name: Add authorized deploy key
    action: authorized_key user=deploy key=&#39;$FILE(id_rsa.pub)&#39;

 - name: Remove sudo group rights
    action: lineinfile dest=/etc/sudoers regexp=&amp;quot;^%sudo&amp;quot; state=absent

  - name: Add deploy user to sudoers
    action: lineinfile dest=/etc/sudoers regexp=&amp;quot;deploy ALL&amp;quot; line=&amp;quot;deploy ALL=(ALL) ALL&amp;quot; state=present

  - name: Disallow password authentication
    action: lineinfile dest=/etc/ssh/sshd_config regexp=&amp;quot;^PasswordAuthentication&amp;quot; line=&amp;quot;PasswordAuthentication no&amp;quot; state=present
    notify: Restart ssh

  - name: Install unattended-upgrades
    action: apt pkg=unattended-upgrades state=present

  - name: Adjust APT update intervals
    action: copy src=config/apt_periodic dest=/etc/apt/apt.conf.d/10periodic

  - name: Make sure unattended-upgrades only installs from $ubuntu_release-security
    action: lineinfile dest=/etc/apt/apt.conf.d/50unattended-upgrades regexp=&amp;quot;$ubuntu_release-updates&amp;quot; state=absent

  - name: Copy debconf selections so that Postfix can configure itself non-interactively
    copy: src=config/postfix_selections  dest=/tmp/postfix_selections

  - name: Set up Postfix to relay mail
    action: command debconf-set-selections /tmp/postfix_selections

  - name: Install logwatch
    action: apt pkg=logwatch state=installed

  - name: Make logwatch mail $logwatch_email daily
    action: lineinfile dest=/etc/cron.daily/00logwatch regexp=&amp;quot;^/usr/sbin/logwatch&amp;quot; line=&amp;quot;/usr/sbin/logwatch --output mail --mailto $logwatch_email --detail high&amp;quot; state=present create=yes

  - name: Setup ufw
    action: shell ufw allow 22/tcp

  - name: Setup ufw
    action: shell ufw allow 443/tcp

  - name: Setup ufw
    action: shell ufw allow 60023/udp

  - name: Enable ufw
    action: shell echo &#39;y&#39; | ufw enable

  - name: Disallow root SSH access
    action: lineinfile dest=/etc/ssh/sshd_config regexp=&amp;quot;^PermitRootLogin&amp;quot; line=&amp;quot;PermitRootLogin no&amp;quot; state=present
    notify: Restart ssh

  handlers:
  - name: Restart ssh
    action: service name=ssh state=restarted:
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see an Ansible playbook is a simple yaml file with commands. Most commands reference modules (as in &lt;code&gt;action: apt &amp;lt;command&amp;gt;&lt;/code&gt; for the apt package manager) and you can run vanilla shell commands with the &amp;ldquo;shell&amp;rdquo; module. The first order of business in our playbook is to reset our root password to something secure. I&amp;rsquo;m doing this because DigitalOcean creates a random password and emails it. If you&amp;rsquo;ve created your root password by some other (secure) means you can skip changing the root password and just do the new user.&lt;/p&gt;

&lt;p&gt;Ansible takes a hashed password to improve security. The hashing can be done on a Linux box using the supplied Python command (in the comments). The command takes your password (via the terminal) and a config/salt string of the format &lt;code&gt;&amp;lt;algo number&amp;gt;&amp;lt;your salt&amp;gt;&lt;/code&gt; and returns a string of the format &lt;code&gt;&amp;lt;algo number&amp;gt;&amp;lt;your salt&amp;gt;&amp;lt;your hashed password&amp;gt;&lt;/code&gt;. In this case we&amp;rsquo;re using the algo number 6 which corresponds on Linux machines to SHA-512. Nota bene: The algo number 6 on OS X does not correspond to SHA-512 and therefore will produce an incompatible hash. I usually generate the password in my newly installed server by logging in via ssh and running the command.&lt;/p&gt;

&lt;p&gt;After we change our root password we update and upgrade with apt-get and then install some packages. I added the installation of Vim and Mosh to the original playbook. This would be a good place to change/add any software you want on the server.&lt;/p&gt;

&lt;h3 id=&#34;mosh&#34;&gt;Mosh&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;re not familiar with Mosh&lt;sup&gt;3&lt;/sup&gt; already it stands for mobile shell and is an alternative/enhancement to ssh for working on a server remotely. I&amp;rsquo;ve only used it for a little while but it&amp;rsquo;s infinitely nicer than using ssh, especially on high latency connections. Mosh supports local echo for a lot of terminal work and has a nice catch-up animation to show what&amp;rsquo;s happening remotely. It also supports interrupted connections. That means you can work on a dodgy connection or sleep your computer and pick up where you left off. Highly recommended.&lt;/p&gt;

&lt;h3 id=&#34;running-the-playbook&#34;&gt;Running the Playbook&lt;/h3&gt;

&lt;p&gt;Now that we&amp;rsquo;ve sorted out our hashed password, we can go ahead and run our playbook. To run the playbook, use the following command:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ansible-playbook -i hosts.ini bootstrap.yml --user root
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll notice that the last command will disallow root access. If you don&amp;rsquo;t do it last and something fails, you&amp;rsquo;ll need to run the script again, except with a different user. It&amp;rsquo;s much easier to allow root until everything else has completed successfully.&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; &lt;a href=&#34;http://plusbryan.com/my-first-5-minutes-on-a-server-or-essential-security-for-linux-servers&#34;&gt;http://plusbryan.com/my-first-5-minutes-on-a-server-or-essential-security-for-linux-servers&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;2&lt;/sup&gt; &lt;a href=&#34;http://practicalops.com/my-first-5-minutes-on-a-server.html&#34;&gt;http://practicalops.com/my-first-5-minutes-on-a-server.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;3&lt;/sup&gt; &lt;a href=&#34;http://mosh.mit.edu/&#34;&gt;http://mosh.mit.edu/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Implementing Porter Stemmer in Haskell</title>
      <link>http://lattejed.com/pages/implementing-porter-stemmer-in-haskell/</link>
      <pubDate>Mon, 10 Jun 2013 20:14:43 +0700</pubDate>
      
      <guid>http://lattejed.com/pages/implementing-porter-stemmer-in-haskell/</guid>
      <description>

&lt;p&gt;I recently started learning Haskell. Like many programmers who get interested in the language I&amp;rsquo;ve spent as much time studying the language as I have trying to find an excuse to actually use it. It&amp;rsquo;s a somewhat difficult language to learn &amp;ndash; at least if you haven&amp;rsquo;t worked with functional programming before &amp;ndash; and it&amp;rsquo;s not really a go-to language for most situations. Finding a reason to use it can be challenging.&lt;/p&gt;

&lt;p&gt;My answer to this has been to work on projects that don&amp;rsquo;t have an immediate application. For reasons I won&amp;rsquo;t bore you with, I decided to (re)implement Porter&amp;rsquo;s stemming algorithm. The point of a stemming algorithm is to reduce words to common roots, which is often used as a pre-processing step when building a search engine or doing other NLP work. For example, the words &amp;ldquo;stemmer&amp;rdquo;, &amp;ldquo;stemming&amp;rdquo;, &amp;ldquo;stemmed&amp;rdquo; are all based on &amp;ldquo;stem&amp;rdquo; and share a common meaning. Reducing these words to their root, &amp;ldquo;stem&amp;rdquo;, makes processing them further a lot easier.&lt;/p&gt;

&lt;p&gt;Porter&amp;rsquo;s English word stemming algorithm is described &lt;a href=&#34;http://tartarus.org/martin/PorterStemmer/def.txt&#34;&gt;here&lt;/a&gt; and there&amp;rsquo;s a Python implementation &lt;a href=&#34;https://hkn.eecs.berkeley.edu/~dyoo/python/py_lovins/porter.py&#34;&gt;here&lt;/a&gt; and a Haskell implementation &lt;a href=&#34;http://tartarus.org/martin/PorterStemmer/haskell.txt&#34;&gt;here&lt;/a&gt;. I&amp;rsquo;m so new to Haskell (and functional programming) that I wanted access to both the original paper, a version in a language I&amp;rsquo;m familiar with as well as something in Haskell. Having said that, after I worked on this algorithm for a while it became apparent that working from the Python version was actually a hindrance compared to just working from the paper. Since our functional approach will be so different from our imperative approach, one doesn&amp;rsquo;t really inform the other.&lt;/p&gt;

&lt;h3 id=&#34;a-tiny-bit-about-haskell&#34;&gt;A Tiny Bit About Haskell&lt;/h3&gt;

&lt;p&gt;Haskell is a purely functional language. Purely functional means that the functions are pure in a mathematical sense. They&amp;rsquo;re free (with some exceptions) from side effects. If you give a Haskell function a given input, it will always return the same output. Functions are also first class and the main control structure used in the language. It&amp;rsquo;s not a stretch to say that everything is a function in Haskell. Haskell is lazy. An infinite list in Haskell is valid. That&amp;rsquo;s made possible by lazy evaluation, i.e., the nth value of a list isn&amp;rsquo;t &amp;ldquo;created&amp;rdquo; until it&amp;rsquo;s needed.&lt;/p&gt;

&lt;p&gt;Haskell lacks a lot of the stuff you&amp;rsquo;re familiar with if you&amp;rsquo;re coming from an imperative background. For control flow there are conditionals but no loops. If you need to do something repeatedly you&amp;rsquo;ll generally use a recursive function or operate on a list. Haskell doesn&amp;rsquo;t have mutable variables (well it does, but not by default) &amp;ndash; with some exceptions, it doesn&amp;rsquo;t have state. Again, to do most things in Haskell you do so without any mutable state. No local variables inside functions to hold intermediate values (or examine them). No variables further up in scope to hold values between function calls. It&amp;rsquo;s a mad, mad world.&lt;/p&gt;

&lt;p&gt;So why Haskell or functional programming in general? Well Haskell&amp;rsquo;s purity makes it much easier to write bug-free code and write tests for that code. Functions are black boxes that can be tested without elaborate setup or teardown. They can be tested in isolation and will operate the same when working with the rest of the program. Having no side effects has its advantages. It&amp;rsquo;s also a terse language. While it&amp;rsquo;s debatable that writing less code (to do the same thing) makes anyone more productive, it is, at least for me, better to write and read terse languages.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve only scratched the surface here. For a more eloquent and informative overview of the benefits this is a good place to start. While we&amp;rsquo;re talking about learning materials, I can&amp;rsquo;t recommend &lt;a href=&#34;http://learnyouahaskell.com/&#34;&gt;Learn You a Haskell for Great Good&lt;/a&gt; enough. It&amp;rsquo;s humorous and dare I say beautifully illustrated &amp;ndash; at least if you like the doodles of people who are obviously too smart for their own good.&lt;/p&gt;

&lt;h3 id=&#34;let-there-be-stems&#34;&gt;Let There Be Stems&lt;/h3&gt;

&lt;p&gt;Enough bs. Let&amp;rsquo;s write some Haskell. The Porter Stemmer algorithm kind of breaks down like this: We make some definitions (such as what&amp;rsquo;s a consonant or a vowel, how many consonant sequences a word has) and then we apply a series of rules to our word to get its stem. I started with our definition of a consonant and vowel. From the paper, we define them as such:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A \consonant\ in a word is a letter other than A, E, I, O or U, and other than Y preceded by a consonant.
From our Python implementation, this definition is handled like this:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def cons(self, i):
    &amp;quot;&amp;quot;&amp;quot;cons(i) is TRUE &amp;lt;=&amp;gt; b[i] is a consonant.&amp;quot;&amp;quot;&amp;quot;
    if self.b[i] == &#39;a&#39; or self.b[i] == &#39;e&#39; or self.b[i] == &#39;i&#39; or self.b[i] == &#39;o&#39; or self.b[i] == &#39;u&#39;:
        return 0
    if self.b[i] == &#39;y&#39;:
        if i == self.k0:
            return 1
        else:
            return (not self.cons(i - 1))
    return 1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is pretty straightforward. Our function cons returns True (or 1 in this case) if b (our word as a string in an instance variable) at the index in question is in the set &amp;ldquo;aeiou&amp;rdquo; or is both &amp;lsquo;y&amp;rsquo; and the preceding letter is not in the set &amp;ldquo;aeiou&amp;rdquo;. This function isn&amp;rsquo;t particularly elegant but it&amp;rsquo;s easy to understand and it gets the job done. Vowels then are anything where cons returns False.&lt;/p&gt;

&lt;p&gt;There are a couple of problems here for the beginning Haskeller. We don&amp;rsquo;t have our instance variable b for one. The other isn&amp;rsquo;t a problem as much as it is a style or philosophy issue. I think you could argue that accessing lists by index isn&amp;rsquo;t very Haskelly. We have an operator for it, !!, but using it means bounds checking and passing our index along with our string to the function. While this is certainly possible (the Haskell implementation listed here does it exactly that way) I wanted to find a solution that felt more natural in the context.&lt;/p&gt;

&lt;p&gt;My only functional background comes from using the functional features present in Python. Specifically I&amp;rsquo;m comfortable with list comprehension as well as &amp;ldquo;decorating&amp;rdquo; values (in a way similar to the decorate-sort-undecorate pattern in Python) in tuples and &amp;ldquo;zipping&amp;rdquo; lists. In this case we want to not only figure out if the characters in a word are vowel or consonants, we&amp;rsquo;re going to want to look at the patterns of vowels and consonants that exist in a word. This will be useful later in the algorithm. Given this, it seemed natural to figure out the entire word at once and keep that pattern as a string in a tuple along with our original word.&lt;/p&gt;

&lt;p&gt;In Haskell I came up with this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;-- Make a pattern to match the consonants and vowels in a word where a cons is 
-- not &amp;quot;aeiou&amp;quot; or y preceded by a cons e.g., &amp;quot;happy&amp;quot; -&amp;gt; (&amp;quot;happy&amp;quot;, &amp;quot;cvccv&amp;quot;)
wordDesc :: String -&amp;gt; (String, String)
wordDesc str = (str, [corv (a,b,i) | (a,b,i) &amp;lt;- zip3 str (rotateR str) [0..len]])
    where len = length str - 1
          corv (a,b,i)
            | a == &#39;y&#39; &amp;amp;&amp;amp; i /= 0 &amp;amp;&amp;amp; b `notElem` vs = &#39;v&#39;            
            | a `elem` vs = &#39;v&#39;
            | otherwise = &#39;c&#39;
            where vs = &amp;quot;aeiou&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first interesting bit here is &lt;code&gt;wordDesc :: String -&amp;gt; (String, String)&lt;/code&gt;. This is our function&amp;rsquo;s type declaration. These are optional but considered good practice. If we don&amp;rsquo;t explicitly define it, the compiler/interpreter will figure it out for itself. In this case, it says that we&amp;rsquo;re going to take a String and return a tuple &lt;code&gt;(String, String)&lt;/code&gt;. Our first string will be our original word, unchanged, and our second will be the matching pattern of consonant or vowel definitions. If we called it with &amp;ldquo;tree&amp;rdquo;, it would give us (&amp;ldquo;tree&amp;rdquo;, &amp;ldquo;ccvv&amp;rdquo;), since our consonants are &amp;ldquo;tr&amp;rdquo; and our vowels &amp;ldquo;ee&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The meat of this function is the list comprehension &lt;code&gt;[corv (a,b,i) | (a,b,i) &amp;lt;- zip3 str (rotateR str) [0..len]]&lt;/code&gt;. This might be a bit confusing if it&amp;rsquo;s new to you. It&amp;rsquo;s of the form &lt;code&gt;[val | val &amp;lt;- list]&lt;/code&gt;. This is very similar to &lt;code&gt;[val for val in list]&lt;/code&gt; in Python. Our list in this case is actually three lists zipped together, &lt;code&gt;zip3 str (rotateR str) [0..len]&lt;/code&gt;: Our original list (our string), that list rotated one letter to the right and the list 0 to the length of our word (less one since we&amp;rsquo;re zero indexed).&lt;/p&gt;

&lt;p&gt;The first list is obvious, but what are the other two lists for? In the case of a &amp;lsquo;y&amp;rsquo; we have to look at two things: the preceding letter (whether or not it&amp;rsquo;s a consonant) and the index of our &amp;lsquo;y&amp;rsquo;. If our &amp;lsquo;y&amp;rsquo; isn&amp;rsquo;t at the start of a word and has a consonant before it, then it&amp;rsquo;s a vowel for our purposes. Since I didn&amp;rsquo;t want to pass an index into this function I decided to look at the current letter and the previous letter simultaneously. Rotating the list one letter to the right &amp;ldquo;lines up&amp;rdquo; our current and previous letters and in this case makes them available in the variables a and b. We still ended up needing that index to check if we&amp;rsquo;re looking at our first letter or not. Not wanting to belabor the &amp;ldquo;no index&amp;rdquo; edict any further I zipped in a list of index values for that purpose. There is likely another, non-indexed, way to do this but I decided to make a concession and move on. Since we only have index values that match our actual string, we don&amp;rsquo;t have to worry about bounds checking at least.&lt;/p&gt;

&lt;p&gt;The pipes in our function definition are called guards. They&amp;rsquo;re one way Haskell allows us to define conditional statements. The guards are evaluated in order and the provided value is assigned for the first condition that evaluates as true. The otherwise statement is mandatory and defines our default value. There where constructions allow us to define parts of our main function separately to improve readability. In this case we&amp;rsquo;re defining len (the length of our string, zero-indexed) and corv, which returns a &amp;lsquo;c&amp;rsquo; or a &amp;lsquo;v&amp;rsquo; based on the criteria that we&amp;rsquo;ve defined.&lt;/p&gt;

&lt;p&gt;Our rotateR function is simply:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;rotateR :: [a] -&amp;gt; [a]
rotateR [x] = [x]
rotateR xs = last xs : init xs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are some other interesting Haskell bits here. First our type declaration is the variable a instead of a defined type. These are called &amp;ldquo;type variables&amp;rdquo; in Haskell. Our declaration here states that we&amp;rsquo;ll take a list of type a and return a list of that same type. For our purposes, we could have used the declaration &lt;code&gt;rotateR :: String -&amp;gt; String&lt;/code&gt;. Using type variables makes the function more generic.&lt;/p&gt;

&lt;p&gt;The other really interesting thing going on here is called pattern matching. Pattern matching in Haskell allows us to create a set of functions that share a type declaration (and a name) but can return different results based on different attributes of the arguments they&amp;rsquo;re called with. If we call our &lt;code&gt;rotateR&lt;/code&gt; with a list of length one (defined as &lt;code&gt;[x]&lt;/code&gt; here) we&amp;rsquo;ll just return the list unchanged, since a list of length one, rotated, is itself. If we call it with a list of length &amp;gt; 1, we&amp;rsquo;ll actually rotate it. The variable xs in this case means any list. Since the pattern matching is attempted in descending order, our first function will catch all lists of length one and our second function will catch all other lists. This is powerful stuff and makes it very easy to implement recursive functions and deal with edge cases.&lt;/p&gt;

&lt;p&gt;To make this function more robust, we could could add in &lt;code&gt;rotateR []&lt;/code&gt; as a pattern so we could define how the function handles being passed an empty list. This is a common pattern in Haskell.&lt;/p&gt;

&lt;p&gt;This algorithm is broken down into 5 steps which process a word in order. I&amp;rsquo;ll describe how I tackled step one in a moment. Before I do, I&amp;rsquo;ll go over some of the foundational parts of the algorithm that we need in place before we go through the steps.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;rotateR :: [a] -&amp;gt; [a]
rotateR [x] = [x]
rotateR xs = last xs : init xs

-- Make a pattern to match the consonants and vowels in a word where a cons is
-- not &amp;quot;aeiou&amp;quot; or y preceded by a cons e.g., &amp;quot;happy&amp;quot; -&amp;gt; (&amp;quot;happy&amp;quot;, &amp;quot;cvccv&amp;quot;)
wordDesc :: String -&amp;gt; (String, String)
wordDesc str =
    (str, [corv (a,b,i) | (a,b,i) &amp;lt;- zip3 str (rotateR str) [0..len]])
    where len = length str - 1
          corv (a,b,i)
            | a == &#39;y&#39; &amp;amp;&amp;amp; i /= 0 &amp;amp;&amp;amp; b `notElem` vs = &#39;v&#39;
            | a `elem` vs = &#39;v&#39;
            | otherwise = &#39;c&#39;
            where vs = &amp;quot;aeiou&amp;quot;

-- Measure the number of consonant sequences in the word in the form
-- [c]vcvc[v] == 2 where the inner &#39;vc&#39; sequences are counted.
measure :: (String, String) -&amp;gt; Int
measure (_,ds) =
    length $ filter (==&#39;c&#39;) ds&#39;
    where ds&#39; = dropWhile (==&#39;c&#39;) [head a | a &amp;lt;- group ds]

-- Tests if our word or stem ends with a given character
endswith :: (String, String) -&amp;gt; Char -&amp;gt; Bool
endswith (str,_) c = c == last str

-- Tests if our word or stem contains a vowel
hasvowel :: (String, String) -&amp;gt; Bool
hasvowel (_,ds) = &#39;v&#39; `elem` ds

-- Tests if our word or stem ends with a double consonant
endsdblc :: (String, String) -&amp;gt; Bool
endsdblc (str,ds) =
    last ds == &#39;c&#39; &amp;amp;&amp;amp; (last $ init str) == last str

-- Tests if our word or stem ends with the pattern &#39;cvc&#39; and does
-- not end with the characters &#39;x&#39;, &#39;w&#39; or &#39;y&#39;
endscvc :: (String, String) -&amp;gt; Bool
endscvc (str,ds) =
    drop (length ds - 3) ds == &amp;quot;cvc&amp;quot; &amp;amp;&amp;amp; last str `notElem` &amp;quot;xwy&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first two functions here were described in more detail in the last post. To recap: The first rotates a string one character to the right. The second determines which letters in a word are consonants or vowels. How this is would likely be handled in an imperative language would be to keep track of the index of the letter we&amp;rsquo;re currently evaluating so we could subtract 1 from that index and check the previous letter (which we need to do in the case of a &amp;lsquo;y&amp;rsquo;). That is, we need an index to know what character in a string we&amp;rsquo;re evaluating. Haskell does have the operator !! which allows us to access a list by index but as I stated before I thought that was decidedly un-Haskelly. Instead, I opted to turn our string into a tuple where the first would be the word we&amp;rsquo;re stemming and the second would be a string of either &amp;ldquo;c&amp;rdquo; or &amp;ldquo;v&amp;rdquo; to denote consonant or vowel.&lt;/p&gt;

&lt;p&gt;The functions that follow show why I opted to do it this way: The algorithm sometimes wants to evaluate a word based on its constituent letters and sometimes wants to look at the pattern of consonants and vowels in that word. The functions endswith, hasvowel, and endsdblc (double consonant) don&amp;rsquo;t need an explanation. The function measure is a bit more complex. What are we measuring? We&amp;rsquo;re measuring the number of consonant-vowel sequences in a word.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-makefile&#34;&gt;A consonant will be denoted by c, a vowel by v. A list ccc... of length greater than 0 will be 
denoted by C, and a list vvv... of length greater than 0 will be denoted by V. Any word, 
or part of a word, therefore has one of the four forms:

    CVCV ... C
    CVCV ... V
    VCVC ... C
    VCVC ... V

These may all be represented by the single form

    [C]VCVC ... [V]

where the square brackets denote arbitrary presence of their contents.
Using (VC){m} to denote VC repeated m times, this may again be written as

    [C](VC){m}[V]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I&amp;rsquo;ll admit that the &amp;ldquo;denote arbitrary presence of their contents&amp;rdquo; part confused me for quite a while. I had to read through the Python implementation and write my Haskell version before it made sense. It just means those bracketed letters (or letter sequences) may or may not be there. In retrospect I can&amp;rsquo;t figure out why I couldn&amp;rsquo;t figure it out &amp;ndash; other than the fact that &amp;ldquo;arbitrary&amp;rdquo; isn&amp;rsquo;t the correct word.&lt;/p&gt;

&lt;p&gt;So, we need to scan through our word to the first vowel sequence and then count how many times we encounter a consonant sequence. The first part &lt;code&gt;[head a | a &amp;lt;- group ds]&lt;/code&gt; reduces our sequence (say &amp;ldquo;ccvvccvvcc&amp;rdquo;) to its transitions (&amp;ldquo;cvcvc&amp;rdquo;). We do that because for our purposes a &amp;ldquo;cc&amp;rdquo; is the same as &amp;ldquo;c&amp;rdquo;. The group function in Haskell groups like elements together in a list, so &amp;ldquo;aab&amp;rdquo; becomes [&amp;ldquo;aa&amp;rdquo;, &amp;ldquo;b&amp;rdquo;]. At the front of our list comprehension head takes the first of every group [&amp;ldquo;a&amp;rdquo;, &amp;ldquo;b&amp;rdquo;].&lt;/p&gt;

&lt;p&gt;The function &lt;code&gt;dropWhile&lt;/code&gt; will return a list starting from the first element that doesn&amp;rsquo;t match the condition. In this case we&amp;rsquo;ll drop the leading consonant, if any, so &amp;ldquo;cvcv&amp;rdquo; becomes &amp;ldquo;vcv&amp;rdquo;. The function filter operates in a similar way. It will return a list of elements that evaluate to true: &amp;ldquo;vcv&amp;rdquo; becomes &amp;ldquo;c&amp;rdquo;. From there we just count the number of elements in the list to get our measure. Another interesting Haskell operator here: $. The $ operator changes the precedence of the expression that follows. We could rewrite &lt;code&gt;length $ filter (==&#39;c&#39;) ds&#39;&lt;/code&gt; as &lt;code&gt;length (filter (==&#39;c&#39;) ds&#39;)&lt;/code&gt;. Using $ is often cleaner looking.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s illustrative to take a look at the Python version:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Vivake Gupta (v@nano.com)
# http://tartarus.org/martin/PorterStemmer/python.txt

def m(self):
        n = 0
        i = self.k0
        while 1:
            if i &amp;gt; self.j:
                return n
            if not self.cons(i):
                break
            i = i + 1
        i = i + 1
        while 1:
            while 1:
                if i &amp;gt; self.j:
                    return n
                if self.cons(i):
                    break
                i = i + 1
            i = i + 1
            n = n + 1
            while 1:
                if i &amp;gt; self.j:
                    return n
                if not self.cons(i):
                    break
                i = i + 1
            i = i + 1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;measure :: (String, String) -&amp;gt; Int
measure (_,ds) =
    length $ filter (==&#39;c&#39;) ds&#39;
    where ds&#39; = dropWhile (==&#39;c&#39;) [head a | a &amp;lt;- group ds]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Which one is easier to read? To be fair this is a problem that Haskell is ideally suited to. (The Python version could be made more succinct as well. The version here was apparently translated line for line from the C version).&lt;/p&gt;

&lt;p&gt;Ok, now on to the actual steps:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;getstem :: String -&amp;gt; String -&amp;gt; String
getstem str sfx = take (length str - length sfx) str

swapsfx :: String -&amp;gt; String -&amp;gt; String -&amp;gt; String
swapsfx str sfx [] = take (length str - length sfx) str
swapsfx str sfx sfx&#39; = take (length str - length sfx) str ++ sfx&#39;

step1a :: (String, String) -&amp;gt; String
step1a (str,_) = swapsfx str (fst sfxs&#39;) (snd sfxs&#39;)
    where sfxs&#39; = head $ dropWhile (\ss -&amp;gt; not $ fst ss `isSuffixOf` str) sfxs
          sfxs = [
            (&amp;quot;sses&amp;quot;, &amp;quot;ss&amp;quot;),
            (&amp;quot;ies&amp;quot; , &amp;quot;i&amp;quot; ),
            (&amp;quot;ss&amp;quot;  , &amp;quot;ss&amp;quot;),
            (&amp;quot;s&amp;quot;   , &amp;quot;&amp;quot;  ) ]

step1b :: (String, String) -&amp;gt; String
step1b (str,ds)
    | sfx &amp;quot;eed&amp;quot; &amp;amp;&amp;amp; (measure $ wordDesc $ stm &amp;quot;eed&amp;quot;) &amp;gt; 0 = swp &amp;quot;eed&amp;quot; &amp;quot;ee&amp;quot;
    | sfx &amp;quot;ed&amp;quot; &amp;amp;&amp;amp; (hasvowel $ wordDesc $ stm &amp;quot;ed&amp;quot;)  = nf $ swp &amp;quot;ed&amp;quot; &amp;quot;&amp;quot;
    | sfx &amp;quot;ing&amp;quot; &amp;amp;&amp;amp; (hasvowel $ wordDesc $ stm &amp;quot;ing&amp;quot;)  = nf $ swp &amp;quot;ing&amp;quot; &amp;quot;&amp;quot;
    | otherwise = str
    where stm = getstem str
          sfx = (`isSuffixOf` str)
          swp = swapsfx str
          nf = step1b&#39; . wordDesc

step1b&#39; :: (String, String) -&amp;gt; String
step1b&#39; (str,ds)
    | or $ map sfx [&amp;quot;at&amp;quot;, &amp;quot;bl&amp;quot;, &amp;quot;iz&amp;quot;] = e
    | dbl &amp;amp;&amp;amp; (not . or $ map end &amp;quot;lsz&amp;quot;) = init str
    | measure (str,ds) == 1 &amp;amp;&amp;amp; endscvc (str,ds) = e
    | otherwise = str
    where sfx = (`isSuffixOf` str)
          dbl = endsdblc (str,ds)
          end = endswith (str,ds)
          e = str ++ &amp;quot;e&amp;quot;

step1c :: (String, String) -&amp;gt; String
step1c (str,ds)
    | (hasvowel $ wordDesc $ stm &amp;quot;y&amp;quot;) &amp;amp;&amp;amp; end &#39;y&#39; = init str ++ &amp;quot;i&amp;quot;
    | otherwise = str
    where stm = getstem str
          end = endswith (str,ds)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The two helper functions at the top of this section probably don&amp;rsquo;t need an explanation. The first returns a word minus a given suffix. The second swaps a suffix with a new one. The first part of step 1 step1a begins the actual meat of our algorithm. It simply matches our word against the attached list of tuples in descending order. If our word ends with suffix on the left, we replace it with the suffix on the right.&lt;/p&gt;

&lt;p&gt;Steps 2 - 5:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-haskell&#34;&gt;{-
    Step 2
    (m&amp;gt;0) ATIONAL -&amp;gt;  ATE
    ...
    (m&amp;gt;0) BILITI  -&amp;gt;  BLE
-}
step2 :: String -&amp;gt; String
step2 str =
    if (not $ null sfxs&#39;) &amp;amp;&amp;amp; (measure $ snd $ wordDesc $ stm (fst sfx)) &amp;gt; 0
    then swapsfx str (fst sfx) (snd sfx)
    else str
    where f = \ss -&amp;gt; not $ fst ss `isSuffixOf` toLowers str
          stm = getstem str
          sfx = head $ sfxs&#39;
          sfxs&#39; = dropWhile f sfxs
          sfxs = [
            (&amp;quot;ational&amp;quot;, &amp;quot;ate&amp;quot; ),
            (&amp;quot;tional&amp;quot; , &amp;quot;tion&amp;quot;),
            (&amp;quot;enci&amp;quot;   , &amp;quot;ence&amp;quot;),
            (&amp;quot;anci&amp;quot;   , &amp;quot;ance&amp;quot;),
            (&amp;quot;izer&amp;quot;   , &amp;quot;ize&amp;quot; ),
            (&amp;quot;abli&amp;quot;   , &amp;quot;able&amp;quot;),
            (&amp;quot;alli&amp;quot;   , &amp;quot;al&amp;quot;  ),
            (&amp;quot;entli&amp;quot;  , &amp;quot;ent&amp;quot; ),
            (&amp;quot;eli&amp;quot;    , &amp;quot;e&amp;quot;   ),
            (&amp;quot;ousli&amp;quot;  , &amp;quot;ous&amp;quot; ),
            (&amp;quot;ization&amp;quot;, &amp;quot;ize&amp;quot; ),
            (&amp;quot;ation&amp;quot;  , &amp;quot;ate&amp;quot; ),
            (&amp;quot;ator&amp;quot;   , &amp;quot;ate&amp;quot; ),
            (&amp;quot;alism&amp;quot;  , &amp;quot;al&amp;quot;  ),
            (&amp;quot;iveness&amp;quot;, &amp;quot;ive&amp;quot; ),
            (&amp;quot;fulness&amp;quot;, &amp;quot;ful&amp;quot; ),
            (&amp;quot;ousness&amp;quot;, &amp;quot;ous&amp;quot; ),
            (&amp;quot;aliti&amp;quot;  , &amp;quot;al&amp;quot;  ),
            (&amp;quot;iviti&amp;quot;  , &amp;quot;ive&amp;quot; ),
            (&amp;quot;biliti&amp;quot; , &amp;quot;ble&amp;quot; )]

{-
    Step 3
    (m&amp;gt;0) ICATE -&amp;gt;  IC
    ...
    (m&amp;gt;0) NESS  -&amp;gt;
-}
step3 :: String -&amp;gt; String
step3 str =
    if (not $ null sfxs&#39;) &amp;amp;&amp;amp; (measure $ snd $ wordDesc $ stm (fst sfx)) &amp;gt; 0
    then swapsfx str (fst sfx) (snd sfx)
    else str
    where f = \ss -&amp;gt; not $ fst ss `isSuffixOf` toLowers str
          stm = getstem str
          sfx = head $ sfxs&#39;
          sfxs&#39; = dropWhile f sfxs
          sfxs = [
            (&amp;quot;icate&amp;quot;, &amp;quot;ic&amp;quot;),
            (&amp;quot;ative&amp;quot;, &amp;quot;&amp;quot;  ),
            (&amp;quot;alize&amp;quot;, &amp;quot;al&amp;quot;),
            (&amp;quot;iciti&amp;quot;, &amp;quot;ic&amp;quot;),
            (&amp;quot;ical&amp;quot; , &amp;quot;ic&amp;quot;),
            (&amp;quot;ful&amp;quot;  , &amp;quot;&amp;quot;  ),
            (&amp;quot;ness&amp;quot; , &amp;quot;&amp;quot;  )]

{-
    Step 4
    (m&amp;gt;1) AL -&amp;gt;
    ...
    (m&amp;gt;1 and (*S or *T)) ION -&amp;gt;
    ...
    (m&amp;gt;1) IZE  -&amp;gt;
-}
step4 :: String -&amp;gt; String
step4 str =
    if (not $ null sfxs&#39;) &amp;amp;&amp;amp; (measure $ snd $ wordDesc $ stm (fst sfx)) &amp;gt; 1
    then swapsfx str (fst sfx) (snd sfx)
    else str
    where f = \ss -&amp;gt; not $ fst ss `isSuffixOf` toLowers str
          stm = getstem str
          sfx = head $ sfxs&#39;
          sfxs&#39; = dropWhile f sfxs
          sfxs = [
            (&amp;quot;al&amp;quot;   , &amp;quot;&amp;quot; ),
            (&amp;quot;ance&amp;quot; , &amp;quot;&amp;quot; ),
            (&amp;quot;ence&amp;quot; , &amp;quot;&amp;quot; ),
            (&amp;quot;er&amp;quot;   , &amp;quot;&amp;quot; ),
            (&amp;quot;ic&amp;quot;   , &amp;quot;&amp;quot; ),
            (&amp;quot;able&amp;quot; , &amp;quot;&amp;quot; ),
            (&amp;quot;ible&amp;quot; , &amp;quot;&amp;quot; ),
            (&amp;quot;ant&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;ement&amp;quot;, &amp;quot;&amp;quot; ),
            (&amp;quot;ment&amp;quot; , &amp;quot;&amp;quot; ),
            (&amp;quot;ent&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;sion&amp;quot; , &amp;quot;s&amp;quot;),
            (&amp;quot;tion&amp;quot; , &amp;quot;t&amp;quot;),
            (&amp;quot;ou&amp;quot;   , &amp;quot;&amp;quot; ),
            (&amp;quot;ism&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;ate&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;iti&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;ous&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;ive&amp;quot;  , &amp;quot;&amp;quot; ),
            (&amp;quot;ize&amp;quot;  , &amp;quot;&amp;quot; )]

{-
    Step 5a
    (m&amp;gt;1) E -&amp;gt;
    (m=1 and not *o) E -&amp;gt;
-}
step5a :: String -&amp;gt; String
step5a str
    | sfx &amp;quot;e&amp;quot; &amp;amp;&amp;amp; (measure $ snd $ wordDesc $ stm &amp;quot;e&amp;quot;) &amp;gt; 1 = swp &amp;quot;e&amp;quot; &amp;quot;&amp;quot;
    | sfx &amp;quot;e&amp;quot; &amp;amp;&amp;amp; (measure $ snd $ wordDesc $ stm &amp;quot;e&amp;quot;) == 1 &amp;amp;&amp;amp; noto = swp &amp;quot;e&amp;quot; &amp;quot;&amp;quot;
    | otherwise = str
    where noto = not $ endscvc $ wordDesc $ stm &amp;quot;e&amp;quot;
          stm = getstem str
          sfx = (`isSuffixOf` toLowers str)
          swp = swapsfx str

{-
    Step 5b
    (m &amp;gt; 1 and *d and *L) -&amp;gt;
-}
step5b :: String -&amp;gt; String
step5b str =
    if (measure $ snd $ wordDesc str) &amp;gt; 1 &amp;amp;&amp;amp; dblc &amp;amp;&amp;amp; ends &#39;l&#39;
    then init str
    else str
    where dblc = endsdblc $ wordDesc str
          ends = endswith str

{-
    Our public stemming function
-}
stem :: String -&amp;gt; String
stem str =
    steps str
    where steps = step5 . step4 . step3 . step2 . step1
          step1 = step1c . step1b . step1a
          step5 = step5b . step5a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As the comments suggest, each function here is the application of a series of rules, mostly with the form &amp;ldquo;(measure&amp;gt;n) SUFFIX -&amp;gt; NEWSUFFIX&amp;rdquo;. What that means in the context of the paper is if the measure of the word&amp;rsquo;s stem (the word minus the first suffix) is over (or equal to) some number, then go ahead and swap the stems. Remember that a word&amp;rsquo;s measure is the number of consonant-vowel sequences in the word. A more thorough explanation is here.&lt;/p&gt;

&lt;p&gt;The general form in my implementation is to use dropWhile against a list of tuples (&amp;ldquo;SUFFIX&amp;rdquo;, &amp;ldquo;NEWSUFFIX&amp;rdquo;). The function dropWhile will return a list that begins with the first element that doesn&amp;rsquo;t satisfy the given condition. In this case we drop all of the tuples where the first part of the tuple doesn&amp;rsquo;t match our word. To check our suffix, Haskell has a function isSuffixOf that does exactly what you would expect.&lt;/p&gt;

&lt;p&gt;The Python version of this algorithm is case-insensitive. I originally was going to make mine case sensitive (it was easier) and convert all input words to lowercase before processing them. As I was wrapping it up I decided I wanted the output to match the Python version so I could compare the two &amp;ndash; so I went back through and made the whole thing case insensitive. Doing so was pretty straightforward. Haskell has a built in function toLower that will lowercase a character. I couldn&amp;rsquo;t find a version that worked on strings so I added the toLowers that does just that.&lt;/p&gt;

&lt;p&gt;The module&amp;rsquo;s exported function stem composes the five main steps (and sub-steps) and returns our stemmed word. Pretty simple.&lt;/p&gt;

&lt;h3 id=&#34;general-observations-about-haskell&#34;&gt;General Observations about Haskell&lt;/h3&gt;

&lt;p&gt;With the algorithm done (but not thoroughly tested yet) I thought this would be a good point to review my initial impressions of working with Haskell. As of the date on this post I&amp;rsquo;ve been working with the language for the equivalent of a few days (in small pieces, when I had the time), which decidedly isn&amp;rsquo;t very much, but I have started to notice some patterns emerge:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Most errors are caught as incompatible type issues.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is great. We can see one of the major benefits of the language&amp;rsquo;s purity and strong, static typing here. For the most part, if you&amp;rsquo;ve screwed up your syntax it will become immediately apparent because a function will be given the wrong number and/or wrong argument types.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Most errors are syntax based.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Following on #1, this might just be that I&amp;rsquo;m really new to the language, but the majority of errors came from the fact that I had written an expression wrong. An common example would be to omit parentheses (or the $ or . operators). The upside here is those are generally easy to fix.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Functions are black boxes that once written and tested, just work.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;While that&amp;rsquo;s not completely true, or at least I wouldn&amp;rsquo;t launch a rocket with that untested assumption, the purity of Haskell functions generally means that once you&amp;rsquo;ve written a function that produces the expected output, you won&amp;rsquo;t have to revisit that function later. The magic here comes from the lack of side effects and typing.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;If you&amp;rsquo;re coming from an imperative-only background, there will be some head scratching, yes, but not that much.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The utter alien-ness of the language is strong at first but dissipates pretty quickly. I would imagine this is especially true if you&amp;rsquo;ve encountered list comprehensions and recursive functions in other languages. While those aren&amp;rsquo;t the entirety of Haskell, they&amp;rsquo;re the right mindset. My entirely unscientific evaluation is that functional languages do stuff &amp;ldquo;in place&amp;rdquo; while imperative languages do stuff &amp;ldquo;in order&amp;rdquo;. It helps me to think of a Haskell module as a single expression (on a single, very long line). While you wouldn&amp;rsquo;t write it that way, I think it&amp;rsquo;s a good mental model to have.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth pointing out that not only are my impressions based on a very short period of time, they&amp;rsquo;re also based on only a subset of the Haskell language. While this module does use the IO Monad, I skipped over working with Haskell&amp;rsquo;s juicier bits like Monads, Haskell&amp;rsquo;s data structures, the Maybe type, etc. I guess my next exercise will be to find a reason to use more of the language.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>